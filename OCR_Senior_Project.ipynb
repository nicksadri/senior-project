{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicksadri/senior-project/blob/main/OCR_Senior_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2YwjdYxqhjV",
        "outputId": "5590a6a9-4b91-4525-8e69-ce6c55b089af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pytorch-CycleGAN-and-pix2pix'...\n",
            "remote: Enumerating objects: 2452, done.\u001b[K\n",
            "remote: Counting objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 2452 (delta 0), reused 1 (delta 0), pack-reused 2451\u001b[K\n",
            "Receiving objects: 100% (2452/2452), 8.18 MiB | 13.60 MiB/s, done.\n",
            "Resolving deltas: 100% (1538/1538), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VcuGXW8nq9I3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('pytorch-CycleGAN-and-pix2pix/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRBoFieRrFkP",
        "outputId": "4463be16-6724-4cc2-9a52-72ab440c6045"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.12.0+cu113)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (0.13.0+cu113)\n",
            "Collecting dominate>=2.4.0\n",
            "  Downloading dominate-2.7.0-py2.py3-none-any.whl (29 kB)\n",
            "Collecting visdom>=0.1.8.8\n",
            "  Downloading visdom-0.1.8.9.tar.gz (676 kB)\n",
            "\u001b[K     |████████████████████████████████| 676 kB 11.1 MB/s \n",
            "\u001b[?25hCollecting wandb\n",
            "  Downloading wandb-0.13.1-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 60.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.7.3)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (5.1.1)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (23.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.15.0)\n",
            "Collecting jsonpatch\n",
            "  Downloading jsonpatch-1.32-py2.py3-none-any.whl (12 kB)\n",
            "Collecting torchfile\n",
            "  Downloading torchfile-0.1.0.tar.gz (5.2 kB)\n",
            "Collecting websocket-client\n",
            "  Downloading websocket_client-1.3.3-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (5.4.8)\n",
            "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (3.17.3)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 33.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (3.13)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (57.4.0)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (2.3)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (7.1.2)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 44.7 MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.0 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5.0->-r requirements.txt (line 2)) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5.0->-r requirements.txt (line 2)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5.0->-r requirements.txt (line 2)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5.0->-r requirements.txt (line 2)) (2.10)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 68.5 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 60.2 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n",
            "\u001b[K     |████████████████████████████████| 156 kB 77.7 MB/s \n",
            "\u001b[?25hCollecting jsonpointer>=1.9\n",
            "  Downloading jsonpointer-2.3-py2.py3-none-any.whl (7.8 kB)\n",
            "Building wheels for collected packages: visdom, pathtools, torchfile\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.1.8.9-py3-none-any.whl size=655250 sha256=7b5c3f56fe7c7bf7267fffb0b37402ecc1955a561796ad326c87980f91606f49\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/d1/9b/cde923274eac9cbb6ff0d8c7c72fe30a3da9095a38fd50bbf1\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=34f41d13965c9b14cff8ff824c46c34fc83f09746133b633842a03b651cee71b\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchfile: filename=torchfile-0.1.0-py3-none-any.whl size=5709 sha256=cc540aacb2ad09316b47c3f6f25c335a9c608ab9e3b2c530b3973c41225052b9\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/5c/3a/a80e1c65880945c71fd833408cd1e9a8cb7e2f8f37620bb75b\n",
            "Successfully built visdom pathtools torchfile\n",
            "Installing collected packages: smmap, jsonpointer, gitdb, websocket-client, torchfile, shortuuid, setproctitle, sentry-sdk, pathtools, jsonpatch, GitPython, docker-pycreds, wandb, visdom, dominate\n",
            "Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 dominate-2.7.0 gitdb-4.0.9 jsonpatch-1.32 jsonpointer-2.3 pathtools-0.1.2 sentry-sdk-1.9.0 setproctitle-1.3.1 shortuuid-1.0.9 smmap-5.0.0 torchfile-0.1.0 visdom-0.1.8.9 wandb-0.13.1 websocket-client-1.3.3\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "jK7-CA4mlWwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1vZx5C11bBZ",
        "outputId": "d062cd5a-9148-4094-e5e6-3806d413b980"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------- Options ---------------\n",
            "               batch_size: 1                             \n",
            "                    beta1: 0.5                           \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "           continue_train: False                         \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ./datasets/denoise_data       \t[default: None]\n",
            "             dataset_mode: unaligned                     \n",
            "                direction: AtoB                          \n",
            "              display_env: main                          \n",
            "             display_freq: 400                           \n",
            "               display_id: 1                             \n",
            "            display_ncols: 4                             \n",
            "             display_port: 8097                          \n",
            "           display_server: http://localhost              \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "              epoch_count: 1                             \n",
            "                 gan_mode: lsgan                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "                 lambda_A: 10.0                          \n",
            "                 lambda_B: 10.0                          \n",
            "          lambda_identity: 0.5                           \n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 286                           \n",
            "                       lr: 0.0002                        \n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: linear                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: cycle_gan                     \n",
            "                 n_epochs: 512                           \t[default: 100]\n",
            "           n_epochs_decay: 100                           \n",
            "               n_layers_D: 3                             \n",
            "                     name: denoise_experiment1           \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_9blocks                \n",
            "                      ngf: 64                            \n",
            "               no_dropout: True                          \n",
            "                  no_flip: False                         \n",
            "                  no_html: False                         \n",
            "                     norm: instance                      \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: train                         \n",
            "                pool_size: 50                            \n",
            "               preprocess: resize_and_crop               \n",
            "               print_freq: 100                           \n",
            "             save_by_iter: False                         \n",
            "          save_epoch_freq: 5                             \n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "         update_html_freq: 1000                          \n",
            "                use_wandb: False                         \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [UnalignedDataset] was created\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "The number of training images = 198\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "model [CycleGANModel] was created\n",
            "---------- Networks initialized -------------\n",
            "[Network G_A] Total number of parameters : 11.378 M\n",
            "[Network G_B] Total number of parameters : 11.378 M\n",
            "[Network D_A] Total number of parameters : 2.765 M\n",
            "[Network D_B] Total number of parameters : 2.765 M\n",
            "-----------------------------------------------\n",
            "Setting up a new session...\n",
            "Exception in user code:\n",
            "------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/connection.py\", line 159, in _new_conn\n",
            "    (self._dns_host, self.port), self.timeout, **extra_kw)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/util/connection.py\", line 80, in create_connection\n",
            "    raise err\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/util/connection.py\", line 70, in create_connection\n",
            "    sock.connect(sa)\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\", line 600, in urlopen\n",
            "    chunked=chunked)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\", line 354, in _make_request\n",
            "    conn.request(method, url, **httplib_request_kw)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1281, in request\n",
            "    self._send_request(method, url, body, headers, encode_chunked)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1327, in _send_request\n",
            "    self.endheaders(body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1276, in endheaders\n",
            "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1036, in _send_output\n",
            "    self.send(msg)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 976, in send\n",
            "    self.connect()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/connection.py\", line 181, in connect\n",
            "    conn = self._new_conn()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/connection.py\", line 168, in _new_conn\n",
            "    self, \"Failed to establish a new connection: %s\" % e)\n",
            "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f2b1af8ac10>: Failed to establish a new connection: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/requests/adapters.py\", line 449, in send\n",
            "    timeout=timeout\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\", line 638, in urlopen\n",
            "    _stacktrace=sys.exc_info()[2])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/util/retry.py\", line 399, in increment\n",
            "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
            "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f2b1af8ac10>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/visdom/__init__.py\", line 711, in _send\n",
            "    data=json.dumps(msg),\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/visdom/__init__.py\", line 677, in _handle_post\n",
            "    r = self.session.post(url, data=data)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/requests/sessions.py\", line 578, in post\n",
            "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/requests/sessions.py\", line 530, in request\n",
            "    resp = self.send(prep, **send_kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/requests/sessions.py\", line 643, in send\n",
            "    r = adapter.send(request, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/requests/adapters.py\", line 516, in send\n",
            "    raise ConnectionError(e, request=request)\n",
            "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f2b1af8ac10>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "[Errno 99] Cannot assign requested address\n",
            "on_close() takes 1 positional argument but 3 were given\n",
            "[Errno 99] Cannot assign requested address\n",
            "on_close() takes 1 positional argument but 3 were given\n",
            "[Errno 99] Cannot assign requested address\n",
            "on_close() takes 1 positional argument but 3 were given\n",
            "Visdom python client failed to establish socket to get messages from the server. This feature is optional and can be disabled by initializing Visdom with `use_incoming_socket=False`, which will prevent waiting for this request to timeout.\n",
            "\n",
            "\n",
            "Could not connect to Visdom server. \n",
            " Trying to start a server....\n",
            "Command: /usr/bin/python3 -m visdom.server -p 8097 &>/dev/null &\n",
            "create web directory ./checkpoints/denoise_experiment1/web...\n",
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "[Errno 99] Cannot assign requested address\n",
            "on_close() takes 1 positional argument but 3 were given\n",
            "(epoch: 1, iters: 100, time: 0.533, data: 0.531) D_A: 0.305 G_A: 0.569 cycle_A: 6.528 idt_A: 0.556 D_B: 1.583 G_B: 0.641 cycle_B: 1.175 idt_B: 3.230 \n",
            "End of epoch 1 / 612 \t Time Taken: 106 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 2, iters: 2, time: 0.578, data: 0.003) D_A: 0.293 G_A: 0.419 cycle_A: 2.525 idt_A: 0.373 D_B: 0.374 G_B: 0.375 cycle_B: 0.820 idt_B: 1.054 \n",
            "(epoch: 2, iters: 102, time: 0.551, data: 0.000) D_A: 0.291 G_A: 0.485 cycle_A: 1.741 idt_A: 0.500 D_B: 0.292 G_B: 0.348 cycle_B: 1.118 idt_B: 0.810 \n",
            "End of epoch 2 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 3, iters: 4, time: 0.804, data: 0.004) D_A: 0.294 G_A: 0.619 cycle_A: 2.150 idt_A: 0.209 D_B: 0.343 G_B: 0.500 cycle_B: 0.448 idt_B: 1.055 \n",
            "(epoch: 3, iters: 104, time: 0.553, data: 0.000) D_A: 0.238 G_A: 0.273 cycle_A: 2.050 idt_A: 0.649 D_B: 0.599 G_B: 1.008 cycle_B: 1.508 idt_B: 0.832 \n",
            "End of epoch 3 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 4, iters: 6, time: 0.555, data: 0.002) D_A: 0.223 G_A: 0.455 cycle_A: 1.360 idt_A: 0.326 D_B: 0.233 G_B: 0.279 cycle_B: 0.769 idt_B: 0.640 \n",
            "(epoch: 4, iters: 106, time: 0.548, data: 0.000) D_A: 0.332 G_A: 0.420 cycle_A: 5.563 idt_A: 0.386 D_B: 0.168 G_B: 0.275 cycle_B: 0.903 idt_B: 2.470 \n",
            "End of epoch 4 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 5, iters: 8, time: 0.848, data: 0.010) D_A: 0.253 G_A: 0.237 cycle_A: 5.657 idt_A: 0.234 D_B: 0.193 G_B: 0.294 cycle_B: 0.526 idt_B: 2.694 \n",
            "(epoch: 5, iters: 108, time: 0.551, data: 0.000) D_A: 0.213 G_A: 0.446 cycle_A: 2.758 idt_A: 0.518 D_B: 0.186 G_B: 0.287 cycle_B: 1.081 idt_B: 1.295 \n",
            "saving the model at the end of epoch 5, iters 990\n",
            "End of epoch 5 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 6, iters: 10, time: 0.553, data: 0.005) D_A: 0.237 G_A: 0.616 cycle_A: 1.270 idt_A: 0.440 D_B: 0.366 G_B: 0.138 cycle_B: 0.985 idt_B: 0.581 \n",
            "(epoch: 6, iters: 110, time: 0.549, data: 0.000) D_A: 0.249 G_A: 0.370 cycle_A: 2.386 idt_A: 0.359 D_B: 0.265 G_B: 0.223 cycle_B: 0.845 idt_B: 1.091 \n",
            "End of epoch 6 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 7, iters: 12, time: 0.878, data: 0.002) D_A: 0.239 G_A: 0.427 cycle_A: 1.742 idt_A: 0.427 D_B: 0.299 G_B: 0.282 cycle_B: 0.893 idt_B: 0.741 \n",
            "(epoch: 7, iters: 112, time: 0.550, data: 0.002) D_A: 0.131 G_A: 0.557 cycle_A: 1.198 idt_A: 0.175 D_B: 0.224 G_B: 0.413 cycle_B: 0.387 idt_B: 0.495 \n",
            "End of epoch 7 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 8, iters: 14, time: 0.554, data: 0.002) D_A: 0.349 G_A: 0.266 cycle_A: 1.269 idt_A: 0.495 D_B: 0.455 G_B: 0.204 cycle_B: 1.110 idt_B: 0.520 \n",
            "(epoch: 8, iters: 114, time: 0.550, data: 0.002) D_A: 0.194 G_A: 0.122 cycle_A: 2.335 idt_A: 0.332 D_B: 0.176 G_B: 0.269 cycle_B: 0.700 idt_B: 1.081 \n",
            "End of epoch 8 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 9, iters: 16, time: 0.847, data: 0.004) D_A: 0.189 G_A: 0.761 cycle_A: 3.490 idt_A: 0.294 D_B: 0.116 G_B: 0.477 cycle_B: 0.736 idt_B: 1.095 \n",
            "(epoch: 9, iters: 116, time: 0.553, data: 0.002) D_A: 0.126 G_A: 0.976 cycle_A: 1.654 idt_A: 0.398 D_B: 0.159 G_B: 0.618 cycle_B: 0.911 idt_B: 0.779 \n",
            "End of epoch 9 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 10, iters: 18, time: 0.538, data: 0.002) D_A: 0.274 G_A: 0.269 cycle_A: 2.666 idt_A: 0.326 D_B: 0.065 G_B: 0.659 cycle_B: 0.754 idt_B: 1.089 \n",
            "(epoch: 10, iters: 118, time: 0.552, data: 0.002) D_A: 0.358 G_A: 0.305 cycle_A: 1.092 idt_A: 0.458 D_B: 0.200 G_B: 0.575 cycle_B: 1.060 idt_B: 0.657 \n",
            "saving the model at the end of epoch 10, iters 1980\n",
            "End of epoch 10 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 11, iters: 20, time: 0.894, data: 0.002) D_A: 0.074 G_A: 0.528 cycle_A: 1.388 idt_A: 0.368 D_B: 0.241 G_B: 0.924 cycle_B: 0.787 idt_B: 0.650 \n",
            "(epoch: 11, iters: 120, time: 0.552, data: 0.002) D_A: 0.257 G_A: 0.301 cycle_A: 1.340 idt_A: 0.290 D_B: 0.312 G_B: 0.369 cycle_B: 0.632 idt_B: 0.496 \n",
            "End of epoch 11 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 12, iters: 22, time: 0.551, data: 0.004) D_A: 0.223 G_A: 0.547 cycle_A: 1.594 idt_A: 0.413 D_B: 0.260 G_B: 0.095 cycle_B: 0.954 idt_B: 0.656 \n",
            "(epoch: 12, iters: 122, time: 0.552, data: 0.002) D_A: 0.039 G_A: 0.197 cycle_A: 2.551 idt_A: 0.377 D_B: 0.260 G_B: 0.316 cycle_B: 0.887 idt_B: 1.176 \n",
            "End of epoch 12 / 612 \t Time Taken: 101 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 13, iters: 24, time: 0.897, data: 0.009) D_A: 0.126 G_A: 0.496 cycle_A: 1.255 idt_A: 0.220 D_B: 0.062 G_B: 0.693 cycle_B: 0.489 idt_B: 0.525 \n",
            "(epoch: 13, iters: 124, time: 0.554, data: 0.002) D_A: 0.247 G_A: 0.249 cycle_A: 2.594 idt_A: 0.203 D_B: 0.338 G_B: 0.119 cycle_B: 0.442 idt_B: 1.459 \n",
            "End of epoch 13 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 14, iters: 26, time: 0.554, data: 0.002) D_A: 0.134 G_A: 1.018 cycle_A: 1.638 idt_A: 0.953 D_B: 0.205 G_B: 0.196 cycle_B: 1.905 idt_B: 0.832 \n",
            "(epoch: 14, iters: 126, time: 0.553, data: 0.002) D_A: 0.316 G_A: 0.202 cycle_A: 1.207 idt_A: 0.657 D_B: 0.242 G_B: 0.334 cycle_B: 1.219 idt_B: 0.516 \n",
            "End of epoch 14 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 15, iters: 28, time: 0.926, data: 0.002) D_A: 0.182 G_A: 0.335 cycle_A: 1.098 idt_A: 0.322 D_B: 0.274 G_B: 0.310 cycle_B: 0.735 idt_B: 0.522 \n",
            "(epoch: 15, iters: 128, time: 0.547, data: 0.002) D_A: 0.215 G_A: 0.223 cycle_A: 1.971 idt_A: 0.460 D_B: 0.231 G_B: 0.207 cycle_B: 0.963 idt_B: 0.937 \n",
            "saving the model at the end of epoch 15, iters 2970\n",
            "End of epoch 15 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 16, iters: 30, time: 0.554, data: 0.002) D_A: 0.139 G_A: 0.612 cycle_A: 3.240 idt_A: 0.291 D_B: 0.149 G_B: 0.706 cycle_B: 1.170 idt_B: 0.732 \n",
            "(epoch: 16, iters: 130, time: 0.554, data: 0.002) D_A: 0.083 G_A: 0.111 cycle_A: 1.979 idt_A: 0.289 D_B: 0.127 G_B: 0.370 cycle_B: 0.816 idt_B: 1.139 \n",
            "End of epoch 16 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 17, iters: 32, time: 0.956, data: 0.005) D_A: 0.326 G_A: 0.371 cycle_A: 1.689 idt_A: 0.351 D_B: 0.277 G_B: 0.222 cycle_B: 0.873 idt_B: 0.667 \n",
            "(epoch: 17, iters: 132, time: 0.550, data: 0.002) D_A: 0.219 G_A: 0.255 cycle_A: 1.908 idt_A: 0.268 D_B: 0.218 G_B: 0.380 cycle_B: 0.632 idt_B: 0.873 \n",
            "End of epoch 17 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 18, iters: 34, time: 0.552, data: 0.002) D_A: 0.269 G_A: 0.341 cycle_A: 1.914 idt_A: 0.403 D_B: 0.228 G_B: 0.393 cycle_B: 0.797 idt_B: 0.840 \n",
            "(epoch: 18, iters: 134, time: 0.551, data: 0.002) D_A: 0.059 G_A: 0.699 cycle_A: 1.699 idt_A: 0.187 D_B: 0.036 G_B: 0.290 cycle_B: 0.469 idt_B: 0.815 \n",
            "End of epoch 18 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 19, iters: 36, time: 0.940, data: 0.002) D_A: 0.281 G_A: 0.239 cycle_A: 3.266 idt_A: 0.293 D_B: 0.132 G_B: 0.483 cycle_B: 0.600 idt_B: 1.472 \n",
            "(epoch: 19, iters: 136, time: 0.543, data: 0.002) D_A: 0.167 G_A: 0.232 cycle_A: 1.143 idt_A: 0.329 D_B: 0.116 G_B: 0.775 cycle_B: 0.694 idt_B: 0.476 \n",
            "End of epoch 19 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 20, iters: 38, time: 0.552, data: 0.013) D_A: 0.393 G_A: 0.728 cycle_A: 1.351 idt_A: 0.216 D_B: 0.141 G_B: 0.792 cycle_B: 0.500 idt_B: 0.539 \n",
            "(epoch: 20, iters: 138, time: 0.545, data: 0.004) D_A: 0.284 G_A: 0.538 cycle_A: 1.317 idt_A: 0.229 D_B: 0.063 G_B: 0.259 cycle_B: 0.513 idt_B: 0.512 \n",
            "saving the model at the end of epoch 20, iters 3960\n",
            "End of epoch 20 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 21, iters: 40, time: 1.037, data: 0.002) D_A: 0.183 G_A: 0.825 cycle_A: 1.014 idt_A: 0.241 D_B: 0.020 G_B: 0.637 cycle_B: 0.518 idt_B: 0.438 \n",
            "(epoch: 21, iters: 140, time: 0.552, data: 0.002) D_A: 0.242 G_A: 0.196 cycle_A: 1.641 idt_A: 0.265 D_B: 0.387 G_B: 0.330 cycle_B: 0.633 idt_B: 0.774 \n",
            "End of epoch 21 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 22, iters: 42, time: 0.559, data: 0.002) D_A: 0.059 G_A: 0.380 cycle_A: 1.531 idt_A: 0.316 D_B: 0.157 G_B: 1.077 cycle_B: 0.730 idt_B: 0.638 \n",
            "(epoch: 22, iters: 142, time: 0.554, data: 0.005) D_A: 0.345 G_A: 0.109 cycle_A: 1.379 idt_A: 0.232 D_B: 0.094 G_B: 0.549 cycle_B: 0.579 idt_B: 0.608 \n",
            "End of epoch 22 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 23, iters: 44, time: 1.114, data: 0.002) D_A: 0.313 G_A: 0.169 cycle_A: 1.183 idt_A: 0.175 D_B: 0.214 G_B: 0.283 cycle_B: 0.409 idt_B: 0.638 \n",
            "(epoch: 23, iters: 144, time: 0.556, data: 0.002) D_A: 0.291 G_A: 0.327 cycle_A: 1.295 idt_A: 0.264 D_B: 0.109 G_B: 0.423 cycle_B: 0.522 idt_B: 0.523 \n",
            "End of epoch 23 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 24, iters: 46, time: 0.549, data: 0.002) D_A: 0.204 G_A: 0.487 cycle_A: 1.761 idt_A: 0.360 D_B: 0.050 G_B: 0.268 cycle_B: 0.854 idt_B: 0.719 \n",
            "(epoch: 24, iters: 146, time: 0.555, data: 0.002) D_A: 0.184 G_A: 0.014 cycle_A: 1.792 idt_A: 0.262 D_B: 0.141 G_B: 0.559 cycle_B: 0.581 idt_B: 0.875 \n",
            "End of epoch 24 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 25, iters: 48, time: 0.956, data: 0.002) D_A: 0.177 G_A: 0.834 cycle_A: 3.078 idt_A: 0.121 D_B: 0.209 G_B: 0.178 cycle_B: 0.270 idt_B: 1.684 \n",
            "(epoch: 25, iters: 148, time: 0.550, data: 0.002) D_A: 0.246 G_A: 0.240 cycle_A: 1.548 idt_A: 0.196 D_B: 0.155 G_B: 0.448 cycle_B: 0.409 idt_B: 0.588 \n",
            "saving the model at the end of epoch 25, iters 4950\n",
            "End of epoch 25 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 26, iters: 50, time: 0.552, data: 0.002) D_A: 0.157 G_A: 0.515 cycle_A: 1.389 idt_A: 0.163 D_B: 0.043 G_B: 0.628 cycle_B: 0.318 idt_B: 0.717 \n",
            "saving the latest model (epoch 26, total_iters 5000)\n",
            "(epoch: 26, iters: 150, time: 0.554, data: 0.002) D_A: 0.196 G_A: 0.288 cycle_A: 2.645 idt_A: 0.194 D_B: 0.054 G_B: 0.417 cycle_B: 0.396 idt_B: 1.331 \n",
            "End of epoch 26 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 27, iters: 52, time: 1.012, data: 0.002) D_A: 0.217 G_A: 0.406 cycle_A: 4.532 idt_A: 0.277 D_B: 0.062 G_B: 0.514 cycle_B: 0.570 idt_B: 2.603 \n",
            "(epoch: 27, iters: 152, time: 0.548, data: 0.002) D_A: 0.227 G_A: 0.461 cycle_A: 1.455 idt_A: 0.607 D_B: 0.292 G_B: 0.040 cycle_B: 1.107 idt_B: 0.598 \n",
            "End of epoch 27 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 28, iters: 54, time: 0.552, data: 0.002) D_A: 0.163 G_A: 0.056 cycle_A: 2.335 idt_A: 0.408 D_B: 0.228 G_B: 0.505 cycle_B: 0.985 idt_B: 1.346 \n",
            "(epoch: 28, iters: 154, time: 0.548, data: 0.002) D_A: 0.159 G_A: 0.631 cycle_A: 1.307 idt_A: 0.203 D_B: 0.068 G_B: 0.800 cycle_B: 0.584 idt_B: 0.450 \n",
            "End of epoch 28 / 612 \t Time Taken: 101 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 29, iters: 56, time: 1.070, data: 0.002) D_A: 0.283 G_A: 0.211 cycle_A: 0.995 idt_A: 0.317 D_B: 0.157 G_B: 0.722 cycle_B: 0.718 idt_B: 0.472 \n",
            "(epoch: 29, iters: 156, time: 0.550, data: 0.003) D_A: 0.143 G_A: 0.472 cycle_A: 1.985 idt_A: 0.244 D_B: 0.056 G_B: 0.586 cycle_B: 0.567 idt_B: 0.858 \n",
            "End of epoch 29 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 30, iters: 58, time: 0.549, data: 0.002) D_A: 0.262 G_A: 0.449 cycle_A: 1.265 idt_A: 0.131 D_B: 0.194 G_B: 0.238 cycle_B: 0.301 idt_B: 0.399 \n",
            "(epoch: 30, iters: 158, time: 0.551, data: 0.004) D_A: 0.061 G_A: 0.514 cycle_A: 1.161 idt_A: 0.092 D_B: 0.030 G_B: 0.384 cycle_B: 0.199 idt_B: 0.491 \n",
            "saving the model at the end of epoch 30, iters 5940\n",
            "End of epoch 30 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 31, iters: 60, time: 1.057, data: 0.002) D_A: 0.202 G_A: 0.230 cycle_A: 2.444 idt_A: 0.255 D_B: 0.141 G_B: 0.561 cycle_B: 0.630 idt_B: 1.115 \n",
            "(epoch: 31, iters: 160, time: 0.549, data: 0.002) D_A: 0.244 G_A: 0.256 cycle_A: 0.749 idt_A: 0.075 D_B: 0.244 G_B: 0.322 cycle_B: 0.155 idt_B: 0.408 \n",
            "End of epoch 31 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 32, iters: 62, time: 0.555, data: 0.002) D_A: 0.136 G_A: 0.827 cycle_A: 1.146 idt_A: 0.220 D_B: 0.176 G_B: 0.366 cycle_B: 0.564 idt_B: 0.442 \n",
            "(epoch: 32, iters: 162, time: 0.550, data: 0.004) D_A: 0.146 G_A: 0.251 cycle_A: 2.149 idt_A: 0.331 D_B: 0.219 G_B: 0.909 cycle_B: 0.661 idt_B: 0.980 \n",
            "End of epoch 32 / 612 \t Time Taken: 101 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 33, iters: 64, time: 0.995, data: 0.002) D_A: 0.212 G_A: 0.814 cycle_A: 1.021 idt_A: 0.083 D_B: 0.070 G_B: 0.676 cycle_B: 0.203 idt_B: 0.371 \n",
            "(epoch: 33, iters: 164, time: 0.555, data: 0.002) D_A: 0.162 G_A: 0.984 cycle_A: 1.788 idt_A: 0.170 D_B: 0.187 G_B: 0.315 cycle_B: 0.400 idt_B: 0.555 \n",
            "End of epoch 33 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 34, iters: 66, time: 0.555, data: 0.005) D_A: 0.079 G_A: 0.406 cycle_A: 0.762 idt_A: 0.240 D_B: 0.381 G_B: 0.776 cycle_B: 0.597 idt_B: 0.268 \n",
            "(epoch: 34, iters: 166, time: 0.552, data: 0.002) D_A: 0.321 G_A: 0.249 cycle_A: 1.147 idt_A: 0.332 D_B: 0.107 G_B: 0.463 cycle_B: 0.671 idt_B: 0.915 \n",
            "End of epoch 34 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 35, iters: 68, time: 1.048, data: 0.015) D_A: 0.083 G_A: 0.568 cycle_A: 2.972 idt_A: 0.235 D_B: 0.071 G_B: 0.475 cycle_B: 0.546 idt_B: 1.812 \n",
            "(epoch: 35, iters: 168, time: 0.550, data: 0.002) D_A: 0.080 G_A: 0.142 cycle_A: 1.972 idt_A: 0.088 D_B: 0.132 G_B: 0.359 cycle_B: 0.230 idt_B: 0.714 \n",
            "saving the model at the end of epoch 35, iters 6930\n",
            "End of epoch 35 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 36, iters: 70, time: 0.553, data: 0.002) D_A: 0.140 G_A: 0.698 cycle_A: 1.029 idt_A: 0.139 D_B: 0.040 G_B: 0.445 cycle_B: 0.307 idt_B: 0.403 \n",
            "(epoch: 36, iters: 170, time: 0.554, data: 0.002) D_A: 0.039 G_A: 0.696 cycle_A: 1.390 idt_A: 0.214 D_B: 0.100 G_B: 0.418 cycle_B: 0.651 idt_B: 0.642 \n",
            "End of epoch 36 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 37, iters: 72, time: 1.063, data: 0.002) D_A: 0.204 G_A: 1.259 cycle_A: 1.771 idt_A: 0.155 D_B: 0.093 G_B: 0.246 cycle_B: 0.453 idt_B: 0.824 \n",
            "(epoch: 37, iters: 172, time: 0.553, data: 0.002) D_A: 0.233 G_A: 0.402 cycle_A: 1.462 idt_A: 0.171 D_B: 0.176 G_B: 0.522 cycle_B: 0.356 idt_B: 0.708 \n",
            "End of epoch 37 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 38, iters: 74, time: 0.552, data: 0.002) D_A: 0.084 G_A: 0.693 cycle_A: 1.162 idt_A: 0.159 D_B: 0.095 G_B: 0.359 cycle_B: 0.383 idt_B: 0.443 \n",
            "(epoch: 38, iters: 174, time: 0.552, data: 0.002) D_A: 0.248 G_A: 0.134 cycle_A: 1.135 idt_A: 0.092 D_B: 0.299 G_B: 0.507 cycle_B: 0.183 idt_B: 0.434 \n",
            "End of epoch 38 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 39, iters: 76, time: 1.330, data: 0.002) D_A: 0.131 G_A: 0.449 cycle_A: 1.071 idt_A: 0.097 D_B: 0.039 G_B: 0.272 cycle_B: 0.219 idt_B: 0.385 \n",
            "(epoch: 39, iters: 176, time: 0.553, data: 0.002) D_A: 0.306 G_A: 0.925 cycle_A: 1.475 idt_A: 0.198 D_B: 0.080 G_B: 0.428 cycle_B: 0.419 idt_B: 0.579 \n",
            "End of epoch 39 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 40, iters: 78, time: 0.553, data: 0.002) D_A: 0.263 G_A: 0.094 cycle_A: 2.261 idt_A: 0.252 D_B: 0.146 G_B: 0.623 cycle_B: 0.588 idt_B: 1.040 \n",
            "(epoch: 40, iters: 178, time: 0.550, data: 0.002) D_A: 0.097 G_A: 0.142 cycle_A: 6.748 idt_A: 0.177 D_B: 0.141 G_B: 0.361 cycle_B: 0.387 idt_B: 3.093 \n",
            "saving the model at the end of epoch 40, iters 7920\n",
            "End of epoch 40 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 41, iters: 80, time: 1.149, data: 0.002) D_A: 0.128 G_A: 0.419 cycle_A: 1.258 idt_A: 0.307 D_B: 0.211 G_B: 0.538 cycle_B: 0.622 idt_B: 0.768 \n",
            "(epoch: 41, iters: 180, time: 0.551, data: 0.002) D_A: 0.065 G_A: 0.263 cycle_A: 3.106 idt_A: 0.295 D_B: 0.127 G_B: 0.486 cycle_B: 0.603 idt_B: 1.212 \n",
            "End of epoch 41 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 42, iters: 82, time: 0.551, data: 0.002) D_A: 0.185 G_A: 0.686 cycle_A: 1.102 idt_A: 0.132 D_B: 0.063 G_B: 0.510 cycle_B: 0.291 idt_B: 0.404 \n",
            "(epoch: 42, iters: 182, time: 0.553, data: 0.006) D_A: 0.145 G_A: 0.285 cycle_A: 1.463 idt_A: 0.199 D_B: 0.291 G_B: 0.602 cycle_B: 0.474 idt_B: 0.830 \n",
            "End of epoch 42 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 43, iters: 84, time: 1.115, data: 0.002) D_A: 0.260 G_A: 0.235 cycle_A: 2.681 idt_A: 0.077 D_B: 0.355 G_B: 0.803 cycle_B: 0.164 idt_B: 1.078 \n",
            "(epoch: 43, iters: 184, time: 0.554, data: 0.002) D_A: 0.047 G_A: 0.682 cycle_A: 1.784 idt_A: 0.284 D_B: 0.091 G_B: 0.550 cycle_B: 0.698 idt_B: 0.689 \n",
            "End of epoch 43 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 44, iters: 86, time: 0.556, data: 0.006) D_A: 0.190 G_A: 0.234 cycle_A: 2.656 idt_A: 0.224 D_B: 0.102 G_B: 1.590 cycle_B: 0.475 idt_B: 1.086 \n",
            "(epoch: 44, iters: 186, time: 0.553, data: 0.004) D_A: 0.195 G_A: 0.057 cycle_A: 2.561 idt_A: 0.307 D_B: 0.237 G_B: 0.464 cycle_B: 0.751 idt_B: 0.905 \n",
            "End of epoch 44 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 45, iters: 88, time: 1.117, data: 0.002) D_A: 0.218 G_A: 0.493 cycle_A: 2.042 idt_A: 0.093 D_B: 0.186 G_B: 0.250 cycle_B: 0.247 idt_B: 0.935 \n",
            "(epoch: 45, iters: 188, time: 0.551, data: 0.002) D_A: 0.192 G_A: 0.942 cycle_A: 1.351 idt_A: 0.198 D_B: 0.148 G_B: 0.494 cycle_B: 0.500 idt_B: 0.440 \n",
            "saving the model at the end of epoch 45, iters 8910\n",
            "End of epoch 45 / 612 \t Time Taken: 104 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 46, iters: 90, time: 0.553, data: 0.002) D_A: 0.114 G_A: 0.594 cycle_A: 1.510 idt_A: 0.099 D_B: 0.040 G_B: 0.684 cycle_B: 0.214 idt_B: 0.528 \n",
            "(epoch: 46, iters: 190, time: 0.555, data: 0.005) D_A: 0.163 G_A: 0.218 cycle_A: 1.071 idt_A: 0.153 D_B: 0.162 G_B: 0.246 cycle_B: 0.338 idt_B: 0.508 \n",
            "End of epoch 46 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 47, iters: 92, time: 1.144, data: 0.002) D_A: 0.081 G_A: 0.460 cycle_A: 1.452 idt_A: 0.388 D_B: 0.106 G_B: 1.056 cycle_B: 0.796 idt_B: 0.675 \n",
            "(epoch: 47, iters: 192, time: 0.555, data: 0.003) D_A: 0.231 G_A: 0.195 cycle_A: 0.999 idt_A: 0.069 D_B: 0.167 G_B: 0.262 cycle_B: 0.173 idt_B: 0.395 \n",
            "End of epoch 47 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 48, iters: 94, time: 0.555, data: 0.002) D_A: 0.111 G_A: 0.892 cycle_A: 0.977 idt_A: 0.218 D_B: 0.046 G_B: 0.788 cycle_B: 0.524 idt_B: 0.321 \n",
            "(epoch: 48, iters: 194, time: 0.552, data: 0.002) D_A: 0.275 G_A: 0.306 cycle_A: 1.178 idt_A: 0.250 D_B: 0.074 G_B: 0.767 cycle_B: 0.605 idt_B: 0.387 \n",
            "End of epoch 48 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 49, iters: 96, time: 1.265, data: 0.002) D_A: 0.277 G_A: 0.577 cycle_A: 2.429 idt_A: 0.269 D_B: 0.267 G_B: 0.340 cycle_B: 0.551 idt_B: 1.014 \n",
            "(epoch: 49, iters: 196, time: 0.555, data: 0.002) D_A: 0.060 G_A: 0.608 cycle_A: 1.200 idt_A: 0.259 D_B: 0.030 G_B: 1.401 cycle_B: 0.526 idt_B: 0.502 \n",
            "End of epoch 49 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 50, iters: 98, time: 0.550, data: 0.002) D_A: 0.164 G_A: 1.127 cycle_A: 1.057 idt_A: 0.101 D_B: 0.026 G_B: 0.675 cycle_B: 0.254 idt_B: 0.355 \n",
            "(epoch: 50, iters: 198, time: 0.553, data: 0.002) D_A: 0.130 G_A: 0.260 cycle_A: 2.631 idt_A: 0.208 D_B: 0.031 G_B: 0.750 cycle_B: 0.568 idt_B: 1.315 \n",
            "saving the model at the end of epoch 50, iters 9900\n",
            "End of epoch 50 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 51, iters: 100, time: 1.276, data: 0.231) D_A: 0.069 G_A: 0.472 cycle_A: 2.475 idt_A: 0.185 D_B: 0.072 G_B: 0.692 cycle_B: 0.507 idt_B: 1.115 \n",
            "saving the latest model (epoch 51, total_iters 10000)\n",
            "End of epoch 51 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 52, iters: 2, time: 0.577, data: 0.005) D_A: 0.293 G_A: 0.266 cycle_A: 2.035 idt_A: 0.232 D_B: 0.100 G_B: 0.374 cycle_B: 0.527 idt_B: 0.803 \n",
            "(epoch: 52, iters: 102, time: 0.554, data: 0.004) D_A: 0.190 G_A: 0.278 cycle_A: 0.514 idt_A: 0.130 D_B: 0.168 G_B: 0.449 cycle_B: 0.316 idt_B: 0.258 \n",
            "End of epoch 52 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 53, iters: 4, time: 0.552, data: 0.003) D_A: 0.211 G_A: 0.762 cycle_A: 1.084 idt_A: 0.188 D_B: 0.073 G_B: 0.454 cycle_B: 0.385 idt_B: 0.401 \n",
            "(epoch: 53, iters: 104, time: 1.210, data: 0.000) D_A: 0.282 G_A: 0.786 cycle_A: 1.128 idt_A: 0.133 D_B: 0.040 G_B: 0.560 cycle_B: 0.300 idt_B: 0.346 \n",
            "End of epoch 53 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 54, iters: 6, time: 0.557, data: 0.003) D_A: 0.063 G_A: 0.976 cycle_A: 0.902 idt_A: 0.256 D_B: 0.042 G_B: 0.589 cycle_B: 0.598 idt_B: 0.289 \n",
            "(epoch: 54, iters: 106, time: 0.550, data: 0.000) D_A: 0.066 G_A: 1.236 cycle_A: 1.439 idt_A: 0.185 D_B: 0.165 G_B: 0.312 cycle_B: 0.537 idt_B: 0.387 \n",
            "End of epoch 54 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 55, iters: 8, time: 0.552, data: 0.002) D_A: 0.319 G_A: 0.711 cycle_A: 0.932 idt_A: 0.139 D_B: 0.049 G_B: 0.617 cycle_B: 0.305 idt_B: 0.361 \n",
            "(epoch: 55, iters: 108, time: 1.227, data: 0.000) D_A: 0.200 G_A: 0.335 cycle_A: 1.014 idt_A: 0.113 D_B: 0.537 G_B: 0.322 cycle_B: 0.271 idt_B: 0.443 \n",
            "saving the model at the end of epoch 55, iters 10890\n",
            "End of epoch 55 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 56, iters: 10, time: 0.550, data: 0.003) D_A: 0.187 G_A: 0.367 cycle_A: 2.104 idt_A: 0.233 D_B: 0.363 G_B: 0.141 cycle_B: 0.493 idt_B: 1.184 \n",
            "(epoch: 56, iters: 110, time: 0.549, data: 0.002) D_A: 0.145 G_A: 0.483 cycle_A: 1.018 idt_A: 0.252 D_B: 0.179 G_B: 0.205 cycle_B: 0.762 idt_B: 0.373 \n",
            "End of epoch 56 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 57, iters: 12, time: 0.550, data: 0.002) D_A: 0.178 G_A: 0.557 cycle_A: 1.368 idt_A: 0.155 D_B: 0.183 G_B: 0.201 cycle_B: 0.339 idt_B: 0.429 \n",
            "(epoch: 57, iters: 112, time: 1.194, data: 0.002) D_A: 0.299 G_A: 0.094 cycle_A: 2.291 idt_A: 0.107 D_B: 0.136 G_B: 0.276 cycle_B: 0.234 idt_B: 0.508 \n",
            "End of epoch 57 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 58, iters: 14, time: 0.548, data: 0.003) D_A: 0.148 G_A: 0.618 cycle_A: 1.059 idt_A: 0.222 D_B: 0.051 G_B: 0.541 cycle_B: 0.361 idt_B: 0.411 \n",
            "(epoch: 58, iters: 114, time: 0.550, data: 0.002) D_A: 0.198 G_A: 0.818 cycle_A: 0.854 idt_A: 0.152 D_B: 0.120 G_B: 0.615 cycle_B: 0.345 idt_B: 0.325 \n",
            "End of epoch 58 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 59, iters: 16, time: 0.554, data: 0.005) D_A: 0.070 G_A: 0.605 cycle_A: 1.758 idt_A: 0.140 D_B: 0.139 G_B: 0.453 cycle_B: 0.302 idt_B: 0.789 \n",
            "(epoch: 59, iters: 116, time: 1.213, data: 0.002) D_A: 0.077 G_A: 0.407 cycle_A: 1.264 idt_A: 0.124 D_B: 0.055 G_B: 0.621 cycle_B: 0.267 idt_B: 0.411 \n",
            "End of epoch 59 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 60, iters: 18, time: 0.554, data: 0.002) D_A: 0.088 G_A: 0.549 cycle_A: 2.578 idt_A: 0.232 D_B: 0.129 G_B: 0.836 cycle_B: 0.605 idt_B: 1.323 \n",
            "(epoch: 60, iters: 118, time: 0.552, data: 0.002) D_A: 0.159 G_A: 0.254 cycle_A: 1.479 idt_A: 0.205 D_B: 0.125 G_B: 1.224 cycle_B: 0.462 idt_B: 1.088 \n",
            "saving the model at the end of epoch 60, iters 11880\n",
            "End of epoch 60 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 61, iters: 20, time: 0.550, data: 0.002) D_A: 0.249 G_A: 0.168 cycle_A: 2.397 idt_A: 0.076 D_B: 0.048 G_B: 0.343 cycle_B: 0.169 idt_B: 1.056 \n",
            "(epoch: 61, iters: 120, time: 1.305, data: 0.005) D_A: 0.029 G_A: 0.308 cycle_A: 2.064 idt_A: 0.184 D_B: 0.146 G_B: 0.739 cycle_B: 0.492 idt_B: 0.963 \n",
            "End of epoch 61 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 62, iters: 22, time: 0.551, data: 0.002) D_A: 0.238 G_A: 0.563 cycle_A: 2.175 idt_A: 0.326 D_B: 0.211 G_B: 0.241 cycle_B: 0.856 idt_B: 0.877 \n",
            "(epoch: 62, iters: 122, time: 0.552, data: 0.007) D_A: 0.092 G_A: 0.662 cycle_A: 2.254 idt_A: 0.110 D_B: 0.108 G_B: 0.614 cycle_B: 0.229 idt_B: 1.024 \n",
            "End of epoch 62 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 63, iters: 24, time: 0.552, data: 0.002) D_A: 0.334 G_A: 1.190 cycle_A: 1.451 idt_A: 0.128 D_B: 0.183 G_B: 0.204 cycle_B: 0.268 idt_B: 0.578 \n",
            "(epoch: 63, iters: 124, time: 1.507, data: 0.002) D_A: 0.044 G_A: 0.530 cycle_A: 0.687 idt_A: 0.198 D_B: 0.093 G_B: 0.702 cycle_B: 0.536 idt_B: 0.434 \n",
            "End of epoch 63 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 64, iters: 26, time: 0.551, data: 0.014) D_A: 0.144 G_A: 0.662 cycle_A: 0.978 idt_A: 0.047 D_B: 0.236 G_B: 0.151 cycle_B: 0.114 idt_B: 0.355 \n",
            "(epoch: 64, iters: 126, time: 0.549, data: 0.006) D_A: 0.095 G_A: 0.480 cycle_A: 0.878 idt_A: 0.127 D_B: 0.442 G_B: 1.051 cycle_B: 0.254 idt_B: 0.279 \n",
            "End of epoch 64 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 65, iters: 28, time: 0.549, data: 0.002) D_A: 0.078 G_A: 0.215 cycle_A: 2.494 idt_A: 0.203 D_B: 0.089 G_B: 0.499 cycle_B: 0.620 idt_B: 1.456 \n",
            "(epoch: 65, iters: 128, time: 1.219, data: 0.006) D_A: 0.079 G_A: 0.452 cycle_A: 1.293 idt_A: 0.105 D_B: 0.019 G_B: 0.908 cycle_B: 0.237 idt_B: 0.359 \n",
            "saving the model at the end of epoch 65, iters 12870\n",
            "End of epoch 65 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 66, iters: 30, time: 0.549, data: 0.006) D_A: 0.068 G_A: 0.386 cycle_A: 3.946 idt_A: 0.154 D_B: 0.052 G_B: 0.659 cycle_B: 0.350 idt_B: 0.938 \n",
            "(epoch: 66, iters: 130, time: 0.548, data: 0.002) D_A: 0.011 G_A: 0.372 cycle_A: 1.324 idt_A: 0.206 D_B: 0.390 G_B: 1.121 cycle_B: 0.522 idt_B: 0.672 \n",
            "End of epoch 66 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 67, iters: 32, time: 0.553, data: 0.002) D_A: 0.186 G_A: 0.316 cycle_A: 1.880 idt_A: 0.131 D_B: 0.107 G_B: 0.401 cycle_B: 0.311 idt_B: 0.818 \n",
            "(epoch: 67, iters: 132, time: 1.264, data: 0.003) D_A: 0.115 G_A: 0.746 cycle_A: 1.084 idt_A: 0.235 D_B: 0.061 G_B: 0.484 cycle_B: 0.537 idt_B: 0.340 \n",
            "End of epoch 67 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 68, iters: 34, time: 0.553, data: 0.002) D_A: 0.028 G_A: 0.723 cycle_A: 1.994 idt_A: 0.305 D_B: 0.152 G_B: 0.623 cycle_B: 0.760 idt_B: 0.673 \n",
            "(epoch: 68, iters: 134, time: 0.550, data: 0.002) D_A: 0.041 G_A: 0.813 cycle_A: 0.730 idt_A: 0.208 D_B: 0.034 G_B: 0.420 cycle_B: 0.608 idt_B: 0.310 \n",
            "End of epoch 68 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 69, iters: 36, time: 0.553, data: 0.003) D_A: 0.048 G_A: 0.464 cycle_A: 0.780 idt_A: 0.243 D_B: 0.009 G_B: 1.002 cycle_B: 0.609 idt_B: 0.275 \n",
            "(epoch: 69, iters: 136, time: 1.352, data: 0.002) D_A: 0.121 G_A: 0.441 cycle_A: 1.242 idt_A: 0.089 D_B: 0.054 G_B: 0.679 cycle_B: 0.239 idt_B: 0.433 \n",
            "End of epoch 69 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 70, iters: 38, time: 0.553, data: 0.004) D_A: 0.115 G_A: 0.146 cycle_A: 2.557 idt_A: 0.218 D_B: 0.099 G_B: 0.483 cycle_B: 0.425 idt_B: 1.047 \n",
            "(epoch: 70, iters: 138, time: 0.545, data: 0.002) D_A: 0.195 G_A: 0.550 cycle_A: 1.082 idt_A: 0.267 D_B: 0.120 G_B: 0.556 cycle_B: 0.589 idt_B: 0.394 \n",
            "saving the model at the end of epoch 70, iters 13860\n",
            "End of epoch 70 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 71, iters: 40, time: 0.544, data: 0.006) D_A: 0.052 G_A: 0.567 cycle_A: 1.088 idt_A: 0.143 D_B: 0.065 G_B: 0.488 cycle_B: 0.357 idt_B: 0.354 \n",
            "(epoch: 71, iters: 140, time: 1.269, data: 0.002) D_A: 0.106 G_A: 0.701 cycle_A: 1.322 idt_A: 0.182 D_B: 0.037 G_B: 0.564 cycle_B: 0.463 idt_B: 0.566 \n",
            "End of epoch 71 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 72, iters: 42, time: 0.551, data: 0.008) D_A: 0.143 G_A: 0.364 cycle_A: 1.314 idt_A: 0.192 D_B: 0.015 G_B: 0.640 cycle_B: 0.424 idt_B: 0.525 \n",
            "(epoch: 72, iters: 142, time: 0.553, data: 0.002) D_A: 0.143 G_A: 0.371 cycle_A: 2.247 idt_A: 0.108 D_B: 0.370 G_B: 0.770 cycle_B: 0.233 idt_B: 1.068 \n",
            "End of epoch 72 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 73, iters: 44, time: 0.554, data: 0.002) D_A: 0.021 G_A: 0.727 cycle_A: 1.239 idt_A: 0.236 D_B: 0.057 G_B: 0.605 cycle_B: 0.509 idt_B: 0.420 \n",
            "(epoch: 73, iters: 144, time: 1.286, data: 0.004) D_A: 0.135 G_A: 0.589 cycle_A: 1.228 idt_A: 0.206 D_B: 0.066 G_B: 0.960 cycle_B: 0.546 idt_B: 0.324 \n",
            "End of epoch 73 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 74, iters: 46, time: 0.555, data: 0.002) D_A: 0.052 G_A: 0.568 cycle_A: 1.230 idt_A: 0.184 D_B: 0.047 G_B: 0.919 cycle_B: 0.435 idt_B: 0.447 \n",
            "(epoch: 74, iters: 146, time: 0.553, data: 0.005) D_A: 0.177 G_A: 0.225 cycle_A: 0.847 idt_A: 0.201 D_B: 0.008 G_B: 0.921 cycle_B: 0.555 idt_B: 0.288 \n",
            "End of epoch 74 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 75, iters: 48, time: 0.541, data: 0.002) D_A: 0.081 G_A: 0.354 cycle_A: 1.015 idt_A: 0.109 D_B: 0.120 G_B: 0.310 cycle_B: 0.285 idt_B: 0.305 \n",
            "(epoch: 75, iters: 148, time: 1.321, data: 0.011) D_A: 0.169 G_A: 1.042 cycle_A: 1.108 idt_A: 0.168 D_B: 0.030 G_B: 0.932 cycle_B: 0.361 idt_B: 0.404 \n",
            "saving the model at the end of epoch 75, iters 14850\n",
            "End of epoch 75 / 612 \t Time Taken: 104 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 76, iters: 50, time: 0.552, data: 0.002) D_A: 0.154 G_A: 0.609 cycle_A: 0.910 idt_A: 0.182 D_B: 0.010 G_B: 1.040 cycle_B: 0.358 idt_B: 0.267 \n",
            "(epoch: 76, iters: 150, time: 0.552, data: 0.002) D_A: 0.343 G_A: 0.268 cycle_A: 0.882 idt_A: 0.269 D_B: 0.463 G_B: 1.028 cycle_B: 0.569 idt_B: 0.419 \n",
            "saving the latest model (epoch 76, total_iters 15000)\n",
            "End of epoch 76 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 77, iters: 52, time: 0.553, data: 0.003) D_A: 0.210 G_A: 0.329 cycle_A: 3.257 idt_A: 0.293 D_B: 0.079 G_B: 0.427 cycle_B: 0.638 idt_B: 1.090 \n",
            "(epoch: 77, iters: 152, time: 1.395, data: 0.002) D_A: 0.252 G_A: 0.174 cycle_A: 1.006 idt_A: 0.167 D_B: 0.048 G_B: 1.302 cycle_B: 0.450 idt_B: 0.432 \n",
            "End of epoch 77 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 78, iters: 54, time: 0.555, data: 0.002) D_A: 0.047 G_A: 0.601 cycle_A: 1.343 idt_A: 0.105 D_B: 0.066 G_B: 0.449 cycle_B: 0.246 idt_B: 0.438 \n",
            "(epoch: 78, iters: 154, time: 0.552, data: 0.006) D_A: 0.132 G_A: 0.491 cycle_A: 1.367 idt_A: 0.106 D_B: 0.059 G_B: 0.564 cycle_B: 0.246 idt_B: 0.347 \n",
            "End of epoch 78 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 79, iters: 56, time: 0.553, data: 0.004) D_A: 0.099 G_A: 0.489 cycle_A: 1.882 idt_A: 0.183 D_B: 0.077 G_B: 0.677 cycle_B: 0.417 idt_B: 0.635 \n",
            "(epoch: 79, iters: 156, time: 1.327, data: 0.005) D_A: 0.252 G_A: 0.237 cycle_A: 1.206 idt_A: 0.131 D_B: 0.016 G_B: 0.649 cycle_B: 0.302 idt_B: 0.378 \n",
            "End of epoch 79 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 80, iters: 58, time: 0.552, data: 0.003) D_A: 0.023 G_A: 0.994 cycle_A: 1.028 idt_A: 0.235 D_B: 0.013 G_B: 0.733 cycle_B: 0.488 idt_B: 0.325 \n",
            "(epoch: 80, iters: 158, time: 0.552, data: 0.002) D_A: 0.206 G_A: 0.307 cycle_A: 1.850 idt_A: 0.113 D_B: 0.158 G_B: 0.345 cycle_B: 0.247 idt_B: 0.478 \n",
            "saving the model at the end of epoch 80, iters 15840\n",
            "End of epoch 80 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 81, iters: 60, time: 0.552, data: 0.005) D_A: 0.024 G_A: 0.992 cycle_A: 1.039 idt_A: 0.186 D_B: 0.328 G_B: 0.293 cycle_B: 0.526 idt_B: 0.304 \n",
            "(epoch: 81, iters: 160, time: 1.375, data: 0.002) D_A: 0.122 G_A: 0.543 cycle_A: 0.747 idt_A: 0.116 D_B: 0.066 G_B: 1.034 cycle_B: 0.311 idt_B: 0.294 \n",
            "End of epoch 81 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 82, iters: 62, time: 0.554, data: 0.002) D_A: 0.039 G_A: 0.825 cycle_A: 1.251 idt_A: 0.220 D_B: 0.203 G_B: 0.339 cycle_B: 0.651 idt_B: 0.356 \n",
            "(epoch: 82, iters: 162, time: 0.554, data: 0.002) D_A: 0.093 G_A: 0.591 cycle_A: 2.196 idt_A: 0.225 D_B: 0.376 G_B: 0.512 cycle_B: 0.506 idt_B: 0.995 \n",
            "End of epoch 82 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 83, iters: 64, time: 0.552, data: 0.005) D_A: 0.048 G_A: 0.432 cycle_A: 1.084 idt_A: 0.153 D_B: 0.027 G_B: 0.617 cycle_B: 0.303 idt_B: 0.319 \n",
            "(epoch: 83, iters: 164, time: 1.369, data: 0.002) D_A: 0.177 G_A: 0.193 cycle_A: 0.817 idt_A: 0.209 D_B: 0.356 G_B: 0.805 cycle_B: 0.538 idt_B: 0.708 \n",
            "End of epoch 83 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 84, iters: 66, time: 0.549, data: 0.004) D_A: 0.113 G_A: 0.287 cycle_A: 1.346 idt_A: 0.123 D_B: 0.223 G_B: 0.378 cycle_B: 0.283 idt_B: 0.588 \n",
            "(epoch: 84, iters: 166, time: 0.553, data: 0.002) D_A: 0.102 G_A: 0.356 cycle_A: 0.925 idt_A: 0.092 D_B: 0.015 G_B: 0.865 cycle_B: 0.177 idt_B: 0.264 \n",
            "End of epoch 84 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 85, iters: 68, time: 0.555, data: 0.002) D_A: 0.021 G_A: 0.018 cycle_A: 2.313 idt_A: 0.211 D_B: 0.251 G_B: 0.218 cycle_B: 0.656 idt_B: 0.831 \n",
            "(epoch: 85, iters: 168, time: 1.494, data: 0.004) D_A: 0.185 G_A: 0.716 cycle_A: 0.714 idt_A: 0.123 D_B: 0.034 G_B: 0.634 cycle_B: 0.263 idt_B: 0.252 \n",
            "saving the model at the end of epoch 85, iters 16830\n",
            "End of epoch 85 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 86, iters: 70, time: 0.556, data: 0.002) D_A: 0.253 G_A: 0.330 cycle_A: 1.923 idt_A: 0.188 D_B: 0.315 G_B: 0.145 cycle_B: 0.375 idt_B: 0.780 \n",
            "(epoch: 86, iters: 170, time: 0.551, data: 0.002) D_A: 0.242 G_A: 0.636 cycle_A: 3.977 idt_A: 0.203 D_B: 0.088 G_B: 0.444 cycle_B: 0.477 idt_B: 1.530 \n",
            "End of epoch 86 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 87, iters: 72, time: 0.552, data: 0.002) D_A: 0.162 G_A: 0.265 cycle_A: 1.870 idt_A: 0.194 D_B: 0.049 G_B: 0.489 cycle_B: 0.524 idt_B: 0.944 \n",
            "(epoch: 87, iters: 172, time: 1.381, data: 0.002) D_A: 0.023 G_A: 0.966 cycle_A: 1.079 idt_A: 0.223 D_B: 0.428 G_B: 0.644 cycle_B: 1.276 idt_B: 0.312 \n",
            "End of epoch 87 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 88, iters: 74, time: 0.548, data: 0.005) D_A: 0.098 G_A: 0.656 cycle_A: 1.316 idt_A: 0.141 D_B: 0.066 G_B: 0.459 cycle_B: 0.300 idt_B: 0.347 \n",
            "(epoch: 88, iters: 174, time: 0.553, data: 0.005) D_A: 0.196 G_A: 0.837 cycle_A: 0.930 idt_A: 0.171 D_B: 0.080 G_B: 0.392 cycle_B: 0.395 idt_B: 0.342 \n",
            "End of epoch 88 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 89, iters: 76, time: 0.552, data: 0.003) D_A: 0.253 G_A: 0.616 cycle_A: 1.384 idt_A: 0.118 D_B: 0.035 G_B: 0.455 cycle_B: 0.265 idt_B: 0.547 \n",
            "(epoch: 89, iters: 176, time: 1.417, data: 0.004) D_A: 0.173 G_A: 0.323 cycle_A: 0.697 idt_A: 0.176 D_B: 0.104 G_B: 0.669 cycle_B: 0.421 idt_B: 0.337 \n",
            "End of epoch 89 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 90, iters: 78, time: 0.553, data: 0.002) D_A: 0.162 G_A: 0.837 cycle_A: 1.221 idt_A: 0.154 D_B: 0.064 G_B: 0.189 cycle_B: 0.348 idt_B: 0.462 \n",
            "(epoch: 90, iters: 178, time: 0.548, data: 0.002) D_A: 0.156 G_A: 0.406 cycle_A: 2.035 idt_A: 0.088 D_B: 0.119 G_B: 0.326 cycle_B: 0.265 idt_B: 0.864 \n",
            "saving the model at the end of epoch 90, iters 17820\n",
            "End of epoch 90 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 91, iters: 80, time: 0.555, data: 0.002) D_A: 0.043 G_A: 0.486 cycle_A: 0.441 idt_A: 0.087 D_B: 0.050 G_B: 0.554 cycle_B: 0.193 idt_B: 0.330 \n",
            "(epoch: 91, iters: 180, time: 1.557, data: 0.006) D_A: 0.121 G_A: 0.210 cycle_A: 1.141 idt_A: 0.193 D_B: 0.136 G_B: 0.734 cycle_B: 0.494 idt_B: 0.352 \n",
            "End of epoch 91 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 92, iters: 82, time: 0.548, data: 0.006) D_A: 0.161 G_A: 0.419 cycle_A: 0.905 idt_A: 0.081 D_B: 0.256 G_B: 0.581 cycle_B: 0.176 idt_B: 0.288 \n",
            "(epoch: 92, iters: 182, time: 0.554, data: 0.002) D_A: 0.161 G_A: 0.453 cycle_A: 2.650 idt_A: 0.111 D_B: 0.159 G_B: 0.390 cycle_B: 0.213 idt_B: 0.928 \n",
            "End of epoch 92 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 93, iters: 84, time: 0.556, data: 0.006) D_A: 0.169 G_A: 0.559 cycle_A: 1.503 idt_A: 0.157 D_B: 0.041 G_B: 0.601 cycle_B: 0.340 idt_B: 0.783 \n",
            "(epoch: 93, iters: 184, time: 1.404, data: 0.001) D_A: 0.258 G_A: 0.714 cycle_A: 1.210 idt_A: 0.144 D_B: 0.106 G_B: 0.131 cycle_B: 0.347 idt_B: 0.465 \n",
            "End of epoch 93 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 94, iters: 86, time: 0.555, data: 0.002) D_A: 0.081 G_A: 0.507 cycle_A: 3.961 idt_A: 0.095 D_B: 0.087 G_B: 0.605 cycle_B: 0.221 idt_B: 0.783 \n",
            "(epoch: 94, iters: 186, time: 0.553, data: 0.002) D_A: 0.121 G_A: 0.456 cycle_A: 0.798 idt_A: 0.176 D_B: 0.286 G_B: 0.202 cycle_B: 0.421 idt_B: 0.518 \n",
            "End of epoch 94 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 95, iters: 88, time: 0.551, data: 0.003) D_A: 0.153 G_A: 0.238 cycle_A: 0.524 idt_A: 0.203 D_B: 0.059 G_B: 0.503 cycle_B: 0.492 idt_B: 0.251 \n",
            "(epoch: 95, iters: 188, time: 1.472, data: 0.003) D_A: 0.114 G_A: 0.494 cycle_A: 2.099 idt_A: 0.268 D_B: 0.194 G_B: 0.843 cycle_B: 0.624 idt_B: 0.452 \n",
            "saving the model at the end of epoch 95, iters 18810\n",
            "End of epoch 95 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 96, iters: 90, time: 0.553, data: 0.003) D_A: 0.061 G_A: 0.475 cycle_A: 2.271 idt_A: 0.077 D_B: 0.022 G_B: 0.833 cycle_B: 0.209 idt_B: 0.707 \n",
            "(epoch: 96, iters: 190, time: 0.558, data: 0.002) D_A: 0.184 G_A: 1.133 cycle_A: 1.531 idt_A: 0.283 D_B: 0.034 G_B: 0.634 cycle_B: 0.645 idt_B: 0.435 \n",
            "End of epoch 96 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 97, iters: 92, time: 0.549, data: 0.002) D_A: 0.050 G_A: 0.614 cycle_A: 1.430 idt_A: 0.185 D_B: 0.184 G_B: 1.042 cycle_B: 0.434 idt_B: 0.458 \n",
            "(epoch: 97, iters: 192, time: 1.532, data: 0.004) D_A: 0.062 G_A: 0.512 cycle_A: 1.200 idt_A: 0.153 D_B: 0.010 G_B: 0.535 cycle_B: 0.353 idt_B: 0.292 \n",
            "End of epoch 97 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 98, iters: 94, time: 0.553, data: 0.002) D_A: 0.048 G_A: 0.570 cycle_A: 1.029 idt_A: 0.118 D_B: 0.053 G_B: 0.549 cycle_B: 0.246 idt_B: 0.319 \n",
            "(epoch: 98, iters: 194, time: 0.552, data: 0.002) D_A: 0.251 G_A: 0.652 cycle_A: 1.224 idt_A: 0.188 D_B: 0.127 G_B: 0.560 cycle_B: 0.360 idt_B: 0.399 \n",
            "End of epoch 98 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 99, iters: 96, time: 0.551, data: 0.002) D_A: 0.071 G_A: 0.490 cycle_A: 1.287 idt_A: 0.093 D_B: 0.022 G_B: 0.827 cycle_B: 0.188 idt_B: 0.498 \n",
            "(epoch: 99, iters: 196, time: 1.478, data: 0.006) D_A: 0.038 G_A: 1.425 cycle_A: 1.150 idt_A: 0.131 D_B: 0.025 G_B: 0.656 cycle_B: 0.297 idt_B: 0.317 \n",
            "End of epoch 99 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 100, iters: 98, time: 0.554, data: 0.002) D_A: 0.157 G_A: 0.723 cycle_A: 1.326 idt_A: 0.157 D_B: 0.024 G_B: 0.329 cycle_B: 0.365 idt_B: 0.340 \n",
            "(epoch: 100, iters: 198, time: 0.550, data: 0.002) D_A: 0.108 G_A: 0.705 cycle_A: 0.835 idt_A: 0.176 D_B: 0.032 G_B: 1.418 cycle_B: 0.423 idt_B: 0.264 \n",
            "saving the model at the end of epoch 100, iters 19800\n",
            "End of epoch 100 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 101, iters: 100, time: 0.550, data: 0.400) D_A: 0.011 G_A: 0.345 cycle_A: 1.050 idt_A: 0.139 D_B: 0.300 G_B: 0.616 cycle_B: 0.338 idt_B: 0.434 \n",
            "End of epoch 101 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 102, iters: 2, time: 1.530, data: 0.003) D_A: 0.074 G_A: 0.517 cycle_A: 1.393 idt_A: 0.174 D_B: 0.310 G_B: 0.444 cycle_B: 0.432 idt_B: 1.359 \n",
            "saving the latest model (epoch 102, total_iters 20000)\n",
            "(epoch: 102, iters: 102, time: 0.554, data: 0.002) D_A: 0.078 G_A: 0.544 cycle_A: 1.080 idt_A: 0.149 D_B: 0.039 G_B: 0.575 cycle_B: 0.343 idt_B: 0.291 \n",
            "End of epoch 102 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 103, iters: 4, time: 0.558, data: 0.002) D_A: 0.228 G_A: 0.136 cycle_A: 2.195 idt_A: 0.161 D_B: 0.398 G_B: 0.040 cycle_B: 0.424 idt_B: 0.771 \n",
            "(epoch: 103, iters: 104, time: 0.553, data: 0.005) D_A: 0.041 G_A: 0.964 cycle_A: 0.807 idt_A: 0.250 D_B: 0.097 G_B: 0.857 cycle_B: 0.680 idt_B: 0.250 \n",
            "End of epoch 103 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 104, iters: 6, time: 1.622, data: 0.001) D_A: 0.102 G_A: 0.395 cycle_A: 0.961 idt_A: 0.267 D_B: 0.090 G_B: 0.105 cycle_B: 0.564 idt_B: 0.435 \n",
            "(epoch: 104, iters: 106, time: 0.556, data: 0.002) D_A: 0.056 G_A: 0.615 cycle_A: 0.858 idt_A: 0.194 D_B: 0.024 G_B: 0.825 cycle_B: 0.474 idt_B: 0.241 \n",
            "End of epoch 104 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 105, iters: 8, time: 0.552, data: 0.002) D_A: 0.365 G_A: 0.574 cycle_A: 0.475 idt_A: 0.162 D_B: 0.095 G_B: 0.528 cycle_B: 0.355 idt_B: 0.349 \n",
            "(epoch: 105, iters: 108, time: 0.546, data: 0.005) D_A: 0.111 G_A: 0.116 cycle_A: 1.574 idt_A: 0.163 D_B: 0.161 G_B: 0.787 cycle_B: 0.375 idt_B: 0.551 \n",
            "saving the model at the end of epoch 105, iters 20790\n",
            "End of epoch 105 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 106, iters: 10, time: 1.510, data: 0.014) D_A: 0.037 G_A: 0.668 cycle_A: 1.045 idt_A: 0.163 D_B: 0.272 G_B: 0.978 cycle_B: 0.398 idt_B: 0.362 \n",
            "(epoch: 106, iters: 110, time: 0.551, data: 0.002) D_A: 0.202 G_A: 0.475 cycle_A: 0.777 idt_A: 0.067 D_B: 0.263 G_B: 0.805 cycle_B: 0.167 idt_B: 0.339 \n",
            "End of epoch 106 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 107, iters: 12, time: 0.553, data: 0.005) D_A: 0.058 G_A: 0.510 cycle_A: 2.125 idt_A: 0.210 D_B: 0.130 G_B: 0.556 cycle_B: 0.481 idt_B: 0.450 \n",
            "(epoch: 107, iters: 112, time: 0.553, data: 0.002) D_A: 0.039 G_A: 0.661 cycle_A: 1.978 idt_A: 0.209 D_B: 0.081 G_B: 0.471 cycle_B: 0.567 idt_B: 0.790 \n",
            "End of epoch 107 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 108, iters: 14, time: 1.519, data: 0.002) D_A: 0.306 G_A: 0.260 cycle_A: 1.269 idt_A: 0.112 D_B: 0.191 G_B: 0.367 cycle_B: 0.248 idt_B: 0.643 \n",
            "(epoch: 108, iters: 114, time: 0.548, data: 0.004) D_A: 0.062 G_A: 0.792 cycle_A: 0.931 idt_A: 0.041 D_B: 0.378 G_B: 0.930 cycle_B: 0.124 idt_B: 0.390 \n",
            "End of epoch 108 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 109, iters: 16, time: 0.548, data: 0.006) D_A: 0.121 G_A: 0.285 cycle_A: 0.884 idt_A: 0.142 D_B: 0.299 G_B: 0.821 cycle_B: 0.339 idt_B: 0.321 \n",
            "(epoch: 109, iters: 116, time: 0.551, data: 0.002) D_A: 0.026 G_A: 0.506 cycle_A: 1.272 idt_A: 0.326 D_B: 0.071 G_B: 0.324 cycle_B: 0.791 idt_B: 0.372 \n",
            "End of epoch 109 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 110, iters: 18, time: 1.580, data: 0.002) D_A: 0.156 G_A: 0.663 cycle_A: 2.577 idt_A: 0.141 D_B: 0.086 G_B: 0.397 cycle_B: 0.406 idt_B: 0.479 \n",
            "(epoch: 110, iters: 118, time: 0.551, data: 0.005) D_A: 0.196 G_A: 0.275 cycle_A: 1.197 idt_A: 0.106 D_B: 0.289 G_B: 0.645 cycle_B: 0.201 idt_B: 0.318 \n",
            "saving the model at the end of epoch 110, iters 21780\n",
            "End of epoch 110 / 612 \t Time Taken: 104 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 111, iters: 20, time: 0.550, data: 0.005) D_A: 0.218 G_A: 0.842 cycle_A: 0.963 idt_A: 0.162 D_B: 0.174 G_B: 0.427 cycle_B: 0.358 idt_B: 0.273 \n",
            "(epoch: 111, iters: 120, time: 0.553, data: 0.005) D_A: 0.069 G_A: 1.355 cycle_A: 0.777 idt_A: 0.130 D_B: 0.027 G_B: 1.019 cycle_B: 0.379 idt_B: 0.230 \n",
            "End of epoch 111 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 112, iters: 22, time: 1.567, data: 0.002) D_A: 0.079 G_A: 0.401 cycle_A: 0.920 idt_A: 0.125 D_B: 0.053 G_B: 0.511 cycle_B: 0.250 idt_B: 0.325 \n",
            "(epoch: 112, iters: 122, time: 0.552, data: 0.002) D_A: 0.126 G_A: 0.977 cycle_A: 0.918 idt_A: 0.098 D_B: 0.025 G_B: 0.905 cycle_B: 0.220 idt_B: 0.237 \n",
            "End of epoch 112 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 113, iters: 24, time: 0.551, data: 0.002) D_A: 0.017 G_A: 1.002 cycle_A: 0.829 idt_A: 0.131 D_B: 0.165 G_B: 0.337 cycle_B: 0.692 idt_B: 0.257 \n",
            "(epoch: 113, iters: 124, time: 0.552, data: 0.004) D_A: 0.120 G_A: 0.752 cycle_A: 1.727 idt_A: 0.195 D_B: 0.100 G_B: 0.492 cycle_B: 0.533 idt_B: 0.736 \n",
            "End of epoch 113 / 612 \t Time Taken: 101 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 114, iters: 26, time: 1.652, data: 0.005) D_A: 0.065 G_A: 0.595 cycle_A: 1.288 idt_A: 0.071 D_B: 0.261 G_B: 0.464 cycle_B: 0.157 idt_B: 0.561 \n",
            "(epoch: 114, iters: 126, time: 0.551, data: 0.002) D_A: 0.193 G_A: 1.369 cycle_A: 0.884 idt_A: 0.083 D_B: 0.030 G_B: 0.674 cycle_B: 0.199 idt_B: 0.494 \n",
            "End of epoch 114 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 115, iters: 28, time: 0.552, data: 0.002) D_A: 0.025 G_A: 0.734 cycle_A: 1.622 idt_A: 0.126 D_B: 0.075 G_B: 0.599 cycle_B: 0.312 idt_B: 0.473 \n",
            "(epoch: 115, iters: 128, time: 0.553, data: 0.006) D_A: 0.022 G_A: 1.216 cycle_A: 1.848 idt_A: 0.170 D_B: 0.067 G_B: 0.594 cycle_B: 0.417 idt_B: 0.430 \n",
            "saving the model at the end of epoch 115, iters 22770\n",
            "End of epoch 115 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 116, iters: 30, time: 1.558, data: 0.002) D_A: 0.054 G_A: 1.017 cycle_A: 1.765 idt_A: 0.145 D_B: 0.087 G_B: 0.040 cycle_B: 0.308 idt_B: 0.507 \n",
            "(epoch: 116, iters: 130, time: 0.553, data: 0.002) D_A: 0.078 G_A: 1.334 cycle_A: 1.732 idt_A: 0.160 D_B: 0.149 G_B: 0.312 cycle_B: 0.424 idt_B: 1.320 \n",
            "End of epoch 116 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 117, iters: 32, time: 0.553, data: 0.002) D_A: 0.143 G_A: 1.130 cycle_A: 0.903 idt_A: 0.092 D_B: 0.098 G_B: 0.334 cycle_B: 0.212 idt_B: 0.333 \n",
            "(epoch: 117, iters: 132, time: 0.553, data: 0.002) D_A: 0.104 G_A: 1.397 cycle_A: 1.195 idt_A: 0.202 D_B: 0.298 G_B: 0.708 cycle_B: 0.552 idt_B: 0.508 \n",
            "End of epoch 117 / 612 \t Time Taken: 101 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 118, iters: 34, time: 1.567, data: 0.002) D_A: 0.068 G_A: 0.239 cycle_A: 1.726 idt_A: 0.180 D_B: 0.111 G_B: 0.297 cycle_B: 0.467 idt_B: 0.654 \n",
            "(epoch: 118, iters: 134, time: 0.551, data: 0.002) D_A: 0.063 G_A: 0.524 cycle_A: 0.943 idt_A: 0.164 D_B: 0.112 G_B: 0.374 cycle_B: 0.477 idt_B: 0.309 \n",
            "End of epoch 118 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 119, iters: 36, time: 0.550, data: 0.005) D_A: 0.246 G_A: 0.675 cycle_A: 1.246 idt_A: 0.139 D_B: 0.055 G_B: 0.568 cycle_B: 0.302 idt_B: 0.309 \n",
            "(epoch: 119, iters: 136, time: 0.554, data: 0.002) D_A: 0.033 G_A: 0.772 cycle_A: 1.208 idt_A: 0.243 D_B: 0.011 G_B: 0.727 cycle_B: 0.539 idt_B: 0.325 \n",
            "End of epoch 119 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 120, iters: 38, time: 1.726, data: 0.002) D_A: 0.018 G_A: 0.297 cycle_A: 0.816 idt_A: 0.095 D_B: 0.401 G_B: 0.738 cycle_B: 0.238 idt_B: 0.299 \n",
            "(epoch: 120, iters: 138, time: 0.553, data: 0.007) D_A: 0.258 G_A: 0.739 cycle_A: 0.563 idt_A: 0.250 D_B: 0.355 G_B: 0.252 cycle_B: 0.544 idt_B: 0.250 \n",
            "saving the model at the end of epoch 120, iters 23760\n",
            "End of epoch 120 / 612 \t Time Taken: 104 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 121, iters: 40, time: 0.552, data: 0.002) D_A: 0.037 G_A: 0.624 cycle_A: 1.478 idt_A: 0.120 D_B: 0.068 G_B: 0.654 cycle_B: 0.277 idt_B: 0.414 \n",
            "(epoch: 121, iters: 140, time: 0.550, data: 0.002) D_A: 0.043 G_A: 1.047 cycle_A: 0.833 idt_A: 0.117 D_B: 0.036 G_B: 0.347 cycle_B: 0.262 idt_B: 0.234 \n",
            "End of epoch 121 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 122, iters: 42, time: 1.582, data: 0.005) D_A: 0.165 G_A: 0.734 cycle_A: 1.025 idt_A: 0.184 D_B: 0.138 G_B: 0.325 cycle_B: 0.457 idt_B: 0.508 \n",
            "(epoch: 122, iters: 142, time: 0.550, data: 0.005) D_A: 0.083 G_A: 1.113 cycle_A: 0.920 idt_A: 0.173 D_B: 0.069 G_B: 0.586 cycle_B: 0.325 idt_B: 0.262 \n",
            "End of epoch 122 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 123, iters: 44, time: 0.553, data: 0.000) D_A: 0.173 G_A: 0.412 cycle_A: 2.442 idt_A: 0.264 D_B: 0.207 G_B: 0.590 cycle_B: 0.577 idt_B: 1.129 \n",
            "(epoch: 123, iters: 144, time: 0.551, data: 0.005) D_A: 0.113 G_A: 0.779 cycle_A: 2.127 idt_A: 0.093 D_B: 0.494 G_B: 0.033 cycle_B: 0.238 idt_B: 0.498 \n",
            "End of epoch 123 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 124, iters: 46, time: 1.710, data: 0.007) D_A: 0.023 G_A: 0.975 cycle_A: 1.002 idt_A: 0.102 D_B: 0.060 G_B: 0.475 cycle_B: 0.256 idt_B: 0.327 \n",
            "(epoch: 124, iters: 146, time: 0.554, data: 0.002) D_A: 0.087 G_A: 1.384 cycle_A: 2.065 idt_A: 0.119 D_B: 0.056 G_B: 0.761 cycle_B: 0.284 idt_B: 0.715 \n",
            "End of epoch 124 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 125, iters: 48, time: 0.554, data: 0.004) D_A: 0.269 G_A: 0.809 cycle_A: 0.945 idt_A: 0.200 D_B: 0.195 G_B: 1.248 cycle_B: 0.447 idt_B: 0.334 \n",
            "(epoch: 125, iters: 148, time: 0.550, data: 0.002) D_A: 0.015 G_A: 0.781 cycle_A: 1.628 idt_A: 0.167 D_B: 0.143 G_B: 0.763 cycle_B: 0.439 idt_B: 0.721 \n",
            "saving the model at the end of epoch 125, iters 24750\n",
            "End of epoch 125 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 126, iters: 50, time: 1.632, data: 0.003) D_A: 0.077 G_A: 0.417 cycle_A: 0.899 idt_A: 0.204 D_B: 0.038 G_B: 1.261 cycle_B: 0.478 idt_B: 0.312 \n",
            "(epoch: 126, iters: 150, time: 0.554, data: 0.002) D_A: 0.039 G_A: 0.264 cycle_A: 0.770 idt_A: 0.163 D_B: 0.333 G_B: 1.118 cycle_B: 0.399 idt_B: 0.285 \n",
            "End of epoch 126 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 127, iters: 52, time: 0.551, data: 0.011) D_A: 0.080 G_A: 0.452 cycle_A: 0.993 idt_A: 0.159 D_B: 0.195 G_B: 0.764 cycle_B: 0.384 idt_B: 0.550 \n",
            "saving the latest model (epoch 127, total_iters 25000)\n",
            "(epoch: 127, iters: 152, time: 0.551, data: 0.006) D_A: 0.193 G_A: 0.205 cycle_A: 0.979 idt_A: 0.082 D_B: 0.159 G_B: 0.481 cycle_B: 0.187 idt_B: 0.647 \n",
            "End of epoch 127 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 128, iters: 54, time: 1.622, data: 0.006) D_A: 0.381 G_A: 0.050 cycle_A: 1.490 idt_A: 0.159 D_B: 0.203 G_B: 0.838 cycle_B: 0.491 idt_B: 0.745 \n",
            "(epoch: 128, iters: 154, time: 0.553, data: 0.002) D_A: 0.179 G_A: 0.256 cycle_A: 1.084 idt_A: 0.119 D_B: 0.110 G_B: 0.881 cycle_B: 0.250 idt_B: 0.280 \n",
            "End of epoch 128 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 129, iters: 56, time: 0.551, data: 0.005) D_A: 0.247 G_A: 2.370 cycle_A: 1.332 idt_A: 0.160 D_B: 0.069 G_B: 0.728 cycle_B: 0.437 idt_B: 0.374 \n",
            "(epoch: 129, iters: 156, time: 0.547, data: 0.006) D_A: 0.117 G_A: 1.205 cycle_A: 1.446 idt_A: 0.104 D_B: 0.109 G_B: 0.372 cycle_B: 0.256 idt_B: 0.374 \n",
            "End of epoch 129 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 130, iters: 58, time: 1.765, data: 0.004) D_A: 0.273 G_A: 0.128 cycle_A: 1.322 idt_A: 0.186 D_B: 0.108 G_B: 0.721 cycle_B: 0.490 idt_B: 0.399 \n",
            "(epoch: 130, iters: 158, time: 0.551, data: 0.003) D_A: 0.080 G_A: 0.619 cycle_A: 1.119 idt_A: 0.091 D_B: 0.235 G_B: 0.142 cycle_B: 0.235 idt_B: 0.405 \n",
            "saving the model at the end of epoch 130, iters 25740\n",
            "End of epoch 130 / 612 \t Time Taken: 104 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 131, iters: 60, time: 0.553, data: 0.005) D_A: 0.027 G_A: 0.722 cycle_A: 0.769 idt_A: 0.171 D_B: 0.094 G_B: 0.542 cycle_B: 0.336 idt_B: 0.248 \n",
            "(epoch: 131, iters: 160, time: 0.554, data: 0.002) D_A: 0.049 G_A: 0.578 cycle_A: 2.770 idt_A: 0.313 D_B: 0.244 G_B: 0.501 cycle_B: 0.655 idt_B: 0.669 \n",
            "End of epoch 131 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 132, iters: 62, time: 1.661, data: 0.005) D_A: 0.191 G_A: 0.763 cycle_A: 0.919 idt_A: 0.130 D_B: 0.107 G_B: 0.336 cycle_B: 0.277 idt_B: 0.299 \n",
            "(epoch: 132, iters: 162, time: 0.552, data: 0.003) D_A: 0.268 G_A: 0.143 cycle_A: 0.552 idt_A: 0.044 D_B: 0.038 G_B: 0.781 cycle_B: 0.144 idt_B: 0.226 \n",
            "End of epoch 132 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 133, iters: 64, time: 0.551, data: 0.006) D_A: 0.027 G_A: 0.591 cycle_A: 1.191 idt_A: 0.152 D_B: 0.083 G_B: 0.829 cycle_B: 0.412 idt_B: 0.299 \n",
            "(epoch: 133, iters: 164, time: 0.545, data: 0.004) D_A: 0.124 G_A: 0.277 cycle_A: 1.100 idt_A: 0.180 D_B: 0.266 G_B: 0.500 cycle_B: 0.378 idt_B: 0.337 \n",
            "End of epoch 133 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 134, iters: 66, time: 1.749, data: 0.002) D_A: 0.033 G_A: 1.262 cycle_A: 0.930 idt_A: 0.175 D_B: 0.119 G_B: 0.531 cycle_B: 0.521 idt_B: 0.321 \n",
            "(epoch: 134, iters: 166, time: 0.555, data: 0.002) D_A: 0.054 G_A: 1.395 cycle_A: 0.903 idt_A: 0.141 D_B: 0.273 G_B: 0.493 cycle_B: 0.308 idt_B: 0.231 \n",
            "End of epoch 134 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 135, iters: 68, time: 0.550, data: 0.002) D_A: 0.230 G_A: 0.222 cycle_A: 1.198 idt_A: 0.074 D_B: 0.040 G_B: 0.811 cycle_B: 0.145 idt_B: 0.345 \n",
            "(epoch: 135, iters: 168, time: 0.550, data: 0.002) D_A: 0.380 G_A: 0.056 cycle_A: 0.756 idt_A: 0.299 D_B: 0.269 G_B: 0.570 cycle_B: 0.829 idt_B: 0.466 \n",
            "saving the model at the end of epoch 135, iters 26730\n",
            "End of epoch 135 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 136, iters: 70, time: 2.041, data: 0.003) D_A: 0.155 G_A: 0.311 cycle_A: 1.699 idt_A: 0.156 D_B: 0.117 G_B: 0.099 cycle_B: 0.313 idt_B: 0.561 \n",
            "(epoch: 136, iters: 170, time: 0.553, data: 0.010) D_A: 0.099 G_A: 0.594 cycle_A: 0.714 idt_A: 0.183 D_B: 0.208 G_B: 0.156 cycle_B: 0.408 idt_B: 0.188 \n",
            "End of epoch 136 / 612 \t Time Taken: 104 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 137, iters: 72, time: 0.554, data: 0.006) D_A: 0.026 G_A: 0.656 cycle_A: 0.892 idt_A: 0.117 D_B: 0.096 G_B: 1.225 cycle_B: 0.270 idt_B: 0.221 \n",
            "(epoch: 137, iters: 172, time: 0.553, data: 0.002) D_A: 0.014 G_A: 1.084 cycle_A: 0.996 idt_A: 0.165 D_B: 0.016 G_B: 0.877 cycle_B: 0.384 idt_B: 0.366 \n",
            "End of epoch 137 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 138, iters: 74, time: 1.798, data: 0.004) D_A: 0.230 G_A: 1.148 cycle_A: 1.423 idt_A: 0.131 D_B: 0.155 G_B: 0.238 cycle_B: 0.301 idt_B: 0.317 \n",
            "(epoch: 138, iters: 174, time: 0.550, data: 0.002) D_A: 0.020 G_A: 0.479 cycle_A: 1.734 idt_A: 0.155 D_B: 0.208 G_B: 0.180 cycle_B: 0.357 idt_B: 0.614 \n",
            "End of epoch 138 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 139, iters: 76, time: 0.546, data: 0.006) D_A: 0.036 G_A: 0.899 cycle_A: 0.698 idt_A: 0.075 D_B: 0.041 G_B: 0.842 cycle_B: 0.176 idt_B: 0.277 \n",
            "(epoch: 139, iters: 176, time: 0.548, data: 0.002) D_A: 0.356 G_A: 0.399 cycle_A: 1.492 idt_A: 0.194 D_B: 0.238 G_B: 0.245 cycle_B: 0.555 idt_B: 0.334 \n",
            "End of epoch 139 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 140, iters: 78, time: 1.711, data: 0.002) D_A: 0.219 G_A: 0.796 cycle_A: 1.204 idt_A: 0.203 D_B: 0.125 G_B: 0.313 cycle_B: 0.543 idt_B: 0.331 \n",
            "(epoch: 140, iters: 178, time: 0.549, data: 0.008) D_A: 0.278 G_A: 0.097 cycle_A: 1.407 idt_A: 0.101 D_B: 0.261 G_B: 0.766 cycle_B: 0.260 idt_B: 0.284 \n",
            "saving the model at the end of epoch 140, iters 27720\n",
            "End of epoch 140 / 612 \t Time Taken: 104 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 141, iters: 80, time: 0.550, data: 0.005) D_A: 0.052 G_A: 0.881 cycle_A: 0.624 idt_A: 0.065 D_B: 0.055 G_B: 0.597 cycle_B: 0.155 idt_B: 0.194 \n",
            "(epoch: 141, iters: 180, time: 0.550, data: 0.002) D_A: 0.024 G_A: 0.834 cycle_A: 0.961 idt_A: 0.034 D_B: 0.019 G_B: 0.451 cycle_B: 0.079 idt_B: 0.273 \n",
            "End of epoch 141 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 142, iters: 82, time: 1.821, data: 0.002) D_A: 0.021 G_A: 1.069 cycle_A: 0.954 idt_A: 0.132 D_B: 0.197 G_B: 0.497 cycle_B: 0.344 idt_B: 0.253 \n",
            "(epoch: 142, iters: 182, time: 0.554, data: 0.004) D_A: 0.040 G_A: 0.566 cycle_A: 0.583 idt_A: 0.242 D_B: 0.093 G_B: 1.124 cycle_B: 0.593 idt_B: 0.261 \n",
            "End of epoch 142 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 143, iters: 84, time: 0.548, data: 0.002) D_A: 0.024 G_A: 1.192 cycle_A: 0.962 idt_A: 0.207 D_B: 0.021 G_B: 0.850 cycle_B: 0.493 idt_B: 0.278 \n",
            "(epoch: 143, iters: 184, time: 0.552, data: 0.002) D_A: 0.054 G_A: 0.456 cycle_A: 1.694 idt_A: 0.088 D_B: 0.145 G_B: 0.721 cycle_B: 0.215 idt_B: 0.789 \n",
            "End of epoch 143 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 144, iters: 86, time: 1.783, data: 0.002) D_A: 0.050 G_A: 0.307 cycle_A: 0.527 idt_A: 0.039 D_B: 0.273 G_B: 0.773 cycle_B: 0.104 idt_B: 0.209 \n",
            "(epoch: 144, iters: 186, time: 0.553, data: 0.003) D_A: 0.045 G_A: 0.497 cycle_A: 0.624 idt_A: 0.074 D_B: 0.054 G_B: 0.621 cycle_B: 0.168 idt_B: 0.250 \n",
            "End of epoch 144 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 145, iters: 88, time: 0.551, data: 0.005) D_A: 0.172 G_A: 0.304 cycle_A: 1.685 idt_A: 0.188 D_B: 0.245 G_B: 0.189 cycle_B: 0.548 idt_B: 0.718 \n",
            "(epoch: 145, iters: 188, time: 0.552, data: 0.002) D_A: 0.011 G_A: 1.012 cycle_A: 0.970 idt_A: 0.134 D_B: 0.117 G_B: 0.413 cycle_B: 0.314 idt_B: 0.261 \n",
            "saving the model at the end of epoch 145, iters 28710\n",
            "End of epoch 145 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 146, iters: 90, time: 1.839, data: 0.002) D_A: 0.028 G_A: 0.634 cycle_A: 1.104 idt_A: 0.197 D_B: 0.028 G_B: 0.943 cycle_B: 0.543 idt_B: 0.278 \n",
            "(epoch: 146, iters: 190, time: 0.552, data: 0.002) D_A: 0.119 G_A: 1.501 cycle_A: 0.981 idt_A: 0.155 D_B: 0.138 G_B: 0.279 cycle_B: 0.482 idt_B: 0.329 \n",
            "End of epoch 146 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 147, iters: 92, time: 0.551, data: 0.002) D_A: 0.032 G_A: 0.655 cycle_A: 1.696 idt_A: 0.107 D_B: 0.191 G_B: 0.353 cycle_B: 0.235 idt_B: 0.561 \n",
            "(epoch: 147, iters: 192, time: 0.555, data: 0.002) D_A: 0.015 G_A: 1.052 cycle_A: 0.752 idt_A: 0.131 D_B: 0.163 G_B: 0.274 cycle_B: 0.406 idt_B: 0.255 \n",
            "End of epoch 147 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 148, iters: 94, time: 1.722, data: 0.002) D_A: 0.028 G_A: 1.112 cycle_A: 1.281 idt_A: 0.122 D_B: 0.102 G_B: 0.724 cycle_B: 0.410 idt_B: 0.385 \n",
            "(epoch: 148, iters: 194, time: 0.549, data: 0.006) D_A: 0.028 G_A: 0.636 cycle_A: 0.855 idt_A: 0.092 D_B: 0.161 G_B: 0.525 cycle_B: 0.204 idt_B: 0.219 \n",
            "End of epoch 148 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 149, iters: 96, time: 0.554, data: 0.002) D_A: 0.175 G_A: 0.249 cycle_A: 1.002 idt_A: 0.274 D_B: 0.082 G_B: 1.042 cycle_B: 0.595 idt_B: 0.258 \n",
            "(epoch: 149, iters: 196, time: 0.554, data: 0.002) D_A: 0.263 G_A: 0.411 cycle_A: 1.690 idt_A: 0.209 D_B: 0.123 G_B: 0.280 cycle_B: 0.474 idt_B: 0.526 \n",
            "End of epoch 149 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 150, iters: 98, time: 1.896, data: 0.002) D_A: 0.037 G_A: 0.897 cycle_A: 0.891 idt_A: 0.127 D_B: 0.176 G_B: 0.378 cycle_B: 0.381 idt_B: 0.237 \n",
            "(epoch: 150, iters: 198, time: 0.555, data: 0.006) D_A: 0.145 G_A: 1.206 cycle_A: 0.927 idt_A: 0.143 D_B: 0.041 G_B: 0.595 cycle_B: 0.319 idt_B: 0.280 \n",
            "saving the model at the end of epoch 150, iters 29700\n",
            "End of epoch 150 / 612 \t Time Taken: 104 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 151, iters: 100, time: 0.553, data: 0.556) D_A: 0.037 G_A: 0.624 cycle_A: 0.877 idt_A: 0.162 D_B: 0.026 G_B: 0.469 cycle_B: 0.444 idt_B: 0.252 \n",
            "End of epoch 151 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 152, iters: 2, time: 0.554, data: 0.006) D_A: 0.123 G_A: 1.571 cycle_A: 0.698 idt_A: 0.096 D_B: 0.132 G_B: 0.286 cycle_B: 0.202 idt_B: 0.202 \n",
            "(epoch: 152, iters: 102, time: 1.843, data: 0.000) D_A: 0.107 G_A: 0.357 cycle_A: 0.899 idt_A: 0.127 D_B: 0.168 G_B: 0.368 cycle_B: 0.326 idt_B: 0.302 \n",
            "saving the latest model (epoch 152, total_iters 30000)\n",
            "End of epoch 152 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 153, iters: 4, time: 0.553, data: 0.002) D_A: 0.297 G_A: 0.387 cycle_A: 0.753 idt_A: 0.120 D_B: 0.225 G_B: 0.219 cycle_B: 0.283 idt_B: 0.346 \n",
            "(epoch: 153, iters: 104, time: 0.552, data: 0.000) D_A: 0.067 G_A: 0.543 cycle_A: 0.705 idt_A: 0.166 D_B: 0.045 G_B: 0.845 cycle_B: 0.512 idt_B: 0.216 \n",
            "End of epoch 153 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 154, iters: 6, time: 0.552, data: 0.005) D_A: 0.046 G_A: 0.472 cycle_A: 1.277 idt_A: 0.103 D_B: 0.158 G_B: 1.064 cycle_B: 0.259 idt_B: 0.517 \n",
            "(epoch: 154, iters: 106, time: 1.876, data: 0.003) D_A: 0.037 G_A: 0.550 cycle_A: 1.701 idt_A: 0.206 D_B: 0.278 G_B: 0.789 cycle_B: 0.564 idt_B: 0.671 \n",
            "End of epoch 154 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 155, iters: 8, time: 0.555, data: 0.006) D_A: 0.014 G_A: 0.846 cycle_A: 0.790 idt_A: 0.146 D_B: 0.141 G_B: 0.778 cycle_B: 0.507 idt_B: 0.332 \n",
            "(epoch: 155, iters: 108, time: 0.547, data: 0.000) D_A: 0.044 G_A: 0.582 cycle_A: 0.760 idt_A: 0.168 D_B: 0.174 G_B: 0.652 cycle_B: 0.373 idt_B: 0.245 \n",
            "saving the model at the end of epoch 155, iters 30690\n",
            "End of epoch 155 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 156, iters: 10, time: 0.547, data: 0.004) D_A: 0.084 G_A: 0.915 cycle_A: 0.799 idt_A: 0.090 D_B: 0.241 G_B: 0.525 cycle_B: 0.205 idt_B: 0.358 \n",
            "(epoch: 156, iters: 110, time: 1.828, data: 0.006) D_A: 0.078 G_A: 0.446 cycle_A: 1.165 idt_A: 0.143 D_B: 0.051 G_B: 0.651 cycle_B: 0.334 idt_B: 0.274 \n",
            "End of epoch 156 / 612 \t Time Taken: 104 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 157, iters: 12, time: 0.546, data: 0.005) D_A: 0.270 G_A: 0.865 cycle_A: 1.350 idt_A: 0.250 D_B: 0.244 G_B: 0.327 cycle_B: 0.503 idt_B: 0.461 \n",
            "(epoch: 157, iters: 112, time: 0.550, data: 0.002) D_A: 0.089 G_A: 0.068 cycle_A: 0.914 idt_A: 0.221 D_B: 0.302 G_B: 0.953 cycle_B: 0.661 idt_B: 0.411 \n",
            "End of epoch 157 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 158, iters: 14, time: 0.555, data: 0.006) D_A: 0.220 G_A: 0.126 cycle_A: 1.079 idt_A: 0.218 D_B: 0.360 G_B: 0.436 cycle_B: 0.381 idt_B: 0.353 \n",
            "(epoch: 158, iters: 114, time: 1.889, data: 0.002) D_A: 0.035 G_A: 0.723 cycle_A: 1.075 idt_A: 0.119 D_B: 0.159 G_B: 0.335 cycle_B: 0.278 idt_B: 0.312 \n",
            "End of epoch 158 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 159, iters: 16, time: 0.554, data: 0.004) D_A: 0.017 G_A: 0.863 cycle_A: 1.123 idt_A: 0.150 D_B: 0.126 G_B: 0.490 cycle_B: 0.409 idt_B: 0.388 \n",
            "(epoch: 159, iters: 116, time: 0.553, data: 0.004) D_A: 0.009 G_A: 1.079 cycle_A: 1.209 idt_A: 0.191 D_B: 0.030 G_B: 0.362 cycle_B: 0.420 idt_B: 0.315 \n",
            "End of epoch 159 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 160, iters: 18, time: 0.549, data: 0.002) D_A: 0.170 G_A: 0.466 cycle_A: 0.888 idt_A: 0.084 D_B: 0.201 G_B: 0.231 cycle_B: 0.177 idt_B: 0.316 \n",
            "(epoch: 160, iters: 118, time: 1.801, data: 0.002) D_A: 0.036 G_A: 0.650 cycle_A: 1.335 idt_A: 0.181 D_B: 0.057 G_B: 0.564 cycle_B: 0.306 idt_B: 0.620 \n",
            "saving the model at the end of epoch 160, iters 31680\n",
            "End of epoch 160 / 612 \t Time Taken: 104 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 161, iters: 20, time: 0.539, data: 0.004) D_A: 0.053 G_A: 0.347 cycle_A: 0.685 idt_A: 0.179 D_B: 0.022 G_B: 1.107 cycle_B: 0.411 idt_B: 0.218 \n",
            "(epoch: 161, iters: 120, time: 0.551, data: 0.002) D_A: 0.047 G_A: 0.178 cycle_A: 0.800 idt_A: 0.179 D_B: 0.105 G_B: 0.704 cycle_B: 0.426 idt_B: 0.301 \n",
            "End of epoch 161 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 162, iters: 22, time: 0.548, data: 0.003) D_A: 0.085 G_A: 0.502 cycle_A: 0.748 idt_A: 0.135 D_B: 0.249 G_B: 0.194 cycle_B: 0.382 idt_B: 0.223 \n",
            "(epoch: 162, iters: 122, time: 1.935, data: 0.002) D_A: 0.234 G_A: 0.723 cycle_A: 2.559 idt_A: 0.115 D_B: 0.056 G_B: 0.457 cycle_B: 0.350 idt_B: 0.491 \n",
            "End of epoch 162 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 163, iters: 24, time: 0.554, data: 0.002) D_A: 0.240 G_A: 0.516 cycle_A: 1.039 idt_A: 0.153 D_B: 0.251 G_B: 0.287 cycle_B: 0.393 idt_B: 0.429 \n",
            "(epoch: 163, iters: 124, time: 0.553, data: 0.002) D_A: 0.034 G_A: 0.544 cycle_A: 1.308 idt_A: 0.163 D_B: 0.041 G_B: 0.445 cycle_B: 0.447 idt_B: 0.437 \n",
            "End of epoch 163 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 164, iters: 26, time: 0.552, data: 0.002) D_A: 0.007 G_A: 0.638 cycle_A: 1.149 idt_A: 0.185 D_B: 0.135 G_B: 0.462 cycle_B: 0.503 idt_B: 0.443 \n",
            "(epoch: 164, iters: 126, time: 1.872, data: 0.004) D_A: 0.040 G_A: 1.218 cycle_A: 1.142 idt_A: 0.099 D_B: 0.075 G_B: 0.661 cycle_B: 0.212 idt_B: 0.315 \n",
            "End of epoch 164 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 165, iters: 28, time: 0.550, data: 0.002) D_A: 0.010 G_A: 1.119 cycle_A: 0.923 idt_A: 0.140 D_B: 0.037 G_B: 0.580 cycle_B: 0.305 idt_B: 0.300 \n",
            "(epoch: 165, iters: 128, time: 0.552, data: 0.002) D_A: 0.206 G_A: 0.484 cycle_A: 1.095 idt_A: 0.117 D_B: 0.022 G_B: 0.318 cycle_B: 0.255 idt_B: 0.292 \n",
            "saving the model at the end of epoch 165, iters 32670\n",
            "End of epoch 165 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 166, iters: 30, time: 0.555, data: 0.005) D_A: 0.055 G_A: 0.896 cycle_A: 1.043 idt_A: 0.093 D_B: 0.036 G_B: 0.700 cycle_B: 0.259 idt_B: 0.333 \n",
            "(epoch: 166, iters: 130, time: 2.019, data: 0.002) D_A: 0.041 G_A: 0.813 cycle_A: 1.306 idt_A: 0.186 D_B: 0.253 G_B: 0.707 cycle_B: 0.376 idt_B: 0.458 \n",
            "End of epoch 166 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 167, iters: 32, time: 0.555, data: 0.002) D_A: 0.276 G_A: 0.101 cycle_A: 0.521 idt_A: 0.161 D_B: 0.045 G_B: 0.813 cycle_B: 0.425 idt_B: 0.192 \n",
            "(epoch: 167, iters: 132, time: 0.551, data: 0.005) D_A: 0.056 G_A: 1.708 cycle_A: 1.032 idt_A: 0.131 D_B: 0.282 G_B: 0.446 cycle_B: 0.347 idt_B: 0.294 \n",
            "End of epoch 167 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 168, iters: 34, time: 0.553, data: 0.005) D_A: 0.098 G_A: 0.370 cycle_A: 1.215 idt_A: 0.391 D_B: 0.091 G_B: 0.921 cycle_B: 0.745 idt_B: 0.433 \n",
            "(epoch: 168, iters: 134, time: 1.878, data: 0.002) D_A: 0.127 G_A: 1.253 cycle_A: 0.940 idt_A: 0.162 D_B: 0.099 G_B: 0.419 cycle_B: 0.353 idt_B: 0.258 \n",
            "End of epoch 168 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 169, iters: 36, time: 0.553, data: 0.002) D_A: 0.163 G_A: 0.204 cycle_A: 0.839 idt_A: 0.167 D_B: 0.291 G_B: 0.633 cycle_B: 0.560 idt_B: 0.467 \n",
            "(epoch: 169, iters: 136, time: 0.538, data: 0.002) D_A: 0.031 G_A: 1.204 cycle_A: 0.885 idt_A: 0.156 D_B: 0.219 G_B: 0.343 cycle_B: 0.439 idt_B: 0.320 \n",
            "End of epoch 169 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 170, iters: 38, time: 0.555, data: 0.009) D_A: 0.046 G_A: 0.846 cycle_A: 1.513 idt_A: 0.107 D_B: 0.077 G_B: 0.872 cycle_B: 0.219 idt_B: 0.648 \n",
            "(epoch: 170, iters: 138, time: 2.007, data: 0.004) D_A: 0.285 G_A: 0.556 cycle_A: 1.196 idt_A: 0.141 D_B: 0.100 G_B: 0.554 cycle_B: 0.244 idt_B: 0.313 \n",
            "saving the model at the end of epoch 170, iters 33660\n",
            "End of epoch 170 / 612 \t Time Taken: 104 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 171, iters: 40, time: 0.555, data: 0.002) D_A: 0.016 G_A: 0.837 cycle_A: 0.709 idt_A: 0.115 D_B: 0.148 G_B: 0.278 cycle_B: 0.329 idt_B: 0.208 \n",
            "(epoch: 171, iters: 140, time: 0.555, data: 0.002) D_A: 0.047 G_A: 0.785 cycle_A: 0.961 idt_A: 0.153 D_B: 0.060 G_B: 0.510 cycle_B: 0.470 idt_B: 0.293 \n",
            "End of epoch 171 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 172, iters: 42, time: 0.554, data: 0.002) D_A: 0.134 G_A: 0.394 cycle_A: 1.445 idt_A: 0.239 D_B: 0.155 G_B: 0.624 cycle_B: 0.531 idt_B: 0.313 \n",
            "(epoch: 172, iters: 142, time: 2.007, data: 0.004) D_A: 0.036 G_A: 1.145 cycle_A: 1.116 idt_A: 0.075 D_B: 0.020 G_B: 0.901 cycle_B: 0.173 idt_B: 0.299 \n",
            "End of epoch 172 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 173, iters: 44, time: 0.552, data: 0.006) D_A: 0.145 G_A: 0.242 cycle_A: 0.787 idt_A: 0.199 D_B: 0.263 G_B: 0.411 cycle_B: 0.431 idt_B: 0.304 \n",
            "(epoch: 173, iters: 144, time: 0.554, data: 0.002) D_A: 0.120 G_A: 0.370 cycle_A: 0.449 idt_A: 0.195 D_B: 0.243 G_B: 0.566 cycle_B: 0.463 idt_B: 0.175 \n",
            "End of epoch 173 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 174, iters: 46, time: 0.552, data: 0.002) D_A: 0.196 G_A: 0.947 cycle_A: 0.729 idt_A: 0.148 D_B: 0.025 G_B: 0.920 cycle_B: 0.425 idt_B: 0.219 \n",
            "(epoch: 174, iters: 146, time: 1.923, data: 0.002) D_A: 0.147 G_A: 0.289 cycle_A: 1.023 idt_A: 0.165 D_B: 0.037 G_B: 0.851 cycle_B: 0.446 idt_B: 0.327 \n",
            "End of epoch 174 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 175, iters: 48, time: 0.555, data: 0.005) D_A: 0.073 G_A: 0.819 cycle_A: 0.736 idt_A: 0.219 D_B: 0.037 G_B: 0.305 cycle_B: 0.662 idt_B: 0.221 \n",
            "(epoch: 175, iters: 148, time: 0.550, data: 0.002) D_A: 0.166 G_A: 0.625 cycle_A: 0.734 idt_A: 0.064 D_B: 0.041 G_B: 0.648 cycle_B: 0.158 idt_B: 0.223 \n",
            "saving the model at the end of epoch 175, iters 34650\n",
            "End of epoch 175 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 176, iters: 50, time: 0.545, data: 0.002) D_A: 0.038 G_A: 0.594 cycle_A: 0.800 idt_A: 0.148 D_B: 0.083 G_B: 0.419 cycle_B: 0.449 idt_B: 0.254 \n",
            "(epoch: 176, iters: 150, time: 2.060, data: 0.002) D_A: 0.083 G_A: 0.852 cycle_A: 0.703 idt_A: 0.143 D_B: 0.046 G_B: 0.595 cycle_B: 0.288 idt_B: 0.228 \n",
            "End of epoch 176 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 177, iters: 52, time: 0.547, data: 0.005) D_A: 0.074 G_A: 0.389 cycle_A: 0.966 idt_A: 0.130 D_B: 0.223 G_B: 0.461 cycle_B: 0.411 idt_B: 0.266 \n",
            "(epoch: 177, iters: 152, time: 0.552, data: 0.002) D_A: 0.088 G_A: 0.684 cycle_A: 1.143 idt_A: 0.170 D_B: 0.103 G_B: 0.492 cycle_B: 0.457 idt_B: 0.467 \n",
            "saving the latest model (epoch 177, total_iters 35000)\n",
            "End of epoch 177 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 178, iters: 54, time: 0.551, data: 0.002) D_A: 0.119 G_A: 0.333 cycle_A: 1.256 idt_A: 0.066 D_B: 0.139 G_B: 0.522 cycle_B: 0.197 idt_B: 0.384 \n",
            "(epoch: 178, iters: 154, time: 1.962, data: 0.002) D_A: 0.154 G_A: 0.762 cycle_A: 0.854 idt_A: 0.147 D_B: 0.046 G_B: 0.615 cycle_B: 0.430 idt_B: 0.220 \n",
            "End of epoch 178 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 179, iters: 56, time: 0.552, data: 0.004) D_A: 0.029 G_A: 0.927 cycle_A: 0.983 idt_A: 0.164 D_B: 0.168 G_B: 0.670 cycle_B: 0.388 idt_B: 0.438 \n",
            "(epoch: 179, iters: 156, time: 0.554, data: 0.002) D_A: 0.016 G_A: 0.848 cycle_A: 1.155 idt_A: 0.154 D_B: 0.034 G_B: 0.957 cycle_B: 0.435 idt_B: 0.681 \n",
            "End of epoch 179 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 180, iters: 58, time: 0.554, data: 0.006) D_A: 0.043 G_A: 0.930 cycle_A: 0.576 idt_A: 0.099 D_B: 0.122 G_B: 0.375 cycle_B: 0.215 idt_B: 0.266 \n",
            "(epoch: 180, iters: 158, time: 2.060, data: 0.003) D_A: 0.006 G_A: 0.951 cycle_A: 0.825 idt_A: 0.161 D_B: 0.097 G_B: 0.571 cycle_B: 0.388 idt_B: 0.393 \n",
            "saving the model at the end of epoch 180, iters 35640\n",
            "End of epoch 180 / 612 \t Time Taken: 104 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 181, iters: 60, time: 0.555, data: 0.007) D_A: 0.118 G_A: 0.819 cycle_A: 1.624 idt_A: 0.129 D_B: 0.214 G_B: 0.307 cycle_B: 0.310 idt_B: 0.272 \n",
            "(epoch: 181, iters: 160, time: 0.548, data: 0.002) D_A: 0.064 G_A: 0.854 cycle_A: 1.106 idt_A: 0.068 D_B: 0.099 G_B: 0.541 cycle_B: 0.179 idt_B: 0.505 \n",
            "End of epoch 181 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 182, iters: 62, time: 0.554, data: 0.002) D_A: 0.043 G_A: 0.908 cycle_A: 0.591 idt_A: 0.279 D_B: 0.062 G_B: 0.600 cycle_B: 0.549 idt_B: 0.221 \n",
            "(epoch: 182, iters: 162, time: 2.077, data: 0.002) D_A: 0.103 G_A: 1.262 cycle_A: 0.846 idt_A: 0.068 D_B: 0.074 G_B: 0.180 cycle_B: 0.162 idt_B: 0.287 \n",
            "End of epoch 182 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 183, iters: 64, time: 0.552, data: 0.006) D_A: 0.043 G_A: 1.433 cycle_A: 0.498 idt_A: 0.142 D_B: 0.226 G_B: 0.425 cycle_B: 0.300 idt_B: 0.291 \n",
            "(epoch: 183, iters: 164, time: 0.553, data: 0.002) D_A: 0.019 G_A: 0.802 cycle_A: 0.712 idt_A: 0.158 D_B: 0.114 G_B: 0.487 cycle_B: 0.375 idt_B: 0.229 \n",
            "End of epoch 183 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 184, iters: 66, time: 0.551, data: 0.002) D_A: 0.009 G_A: 0.916 cycle_A: 0.945 idt_A: 0.092 D_B: 0.048 G_B: 0.608 cycle_B: 0.248 idt_B: 0.315 \n",
            "(epoch: 184, iters: 166, time: 1.973, data: 0.005) D_A: 0.071 G_A: 1.001 cycle_A: 1.873 idt_A: 0.057 D_B: 0.097 G_B: 0.831 cycle_B: 0.172 idt_B: 0.657 \n",
            "End of epoch 184 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 185, iters: 68, time: 0.554, data: 0.005) D_A: 0.373 G_A: 1.037 cycle_A: 0.815 idt_A: 0.256 D_B: 0.078 G_B: 0.539 cycle_B: 0.571 idt_B: 0.307 \n",
            "(epoch: 185, iters: 168, time: 0.549, data: 0.002) D_A: 0.035 G_A: 0.773 cycle_A: 1.295 idt_A: 0.243 D_B: 0.191 G_B: 0.744 cycle_B: 0.612 idt_B: 0.441 \n",
            "saving the model at the end of epoch 185, iters 36630\n",
            "End of epoch 185 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 186, iters: 70, time: 0.555, data: 0.002) D_A: 0.125 G_A: 0.687 cycle_A: 0.670 idt_A: 0.156 D_B: 0.028 G_B: 0.683 cycle_B: 0.412 idt_B: 0.325 \n",
            "(epoch: 186, iters: 170, time: 2.124, data: 0.004) D_A: 0.042 G_A: 0.193 cycle_A: 0.902 idt_A: 0.083 D_B: 0.280 G_B: 0.943 cycle_B: 0.248 idt_B: 0.416 \n",
            "End of epoch 186 / 612 \t Time Taken: 104 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 187, iters: 72, time: 0.553, data: 0.002) D_A: 0.316 G_A: 0.080 cycle_A: 0.929 idt_A: 0.103 D_B: 0.058 G_B: 0.911 cycle_B: 0.252 idt_B: 0.209 \n",
            "(epoch: 187, iters: 172, time: 0.551, data: 0.002) D_A: 0.206 G_A: 0.530 cycle_A: 0.778 idt_A: 0.101 D_B: 0.128 G_B: 0.304 cycle_B: 0.206 idt_B: 0.228 \n",
            "End of epoch 187 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 188, iters: 74, time: 0.552, data: 0.003) D_A: 0.051 G_A: 0.990 cycle_A: 0.485 idt_A: 0.067 D_B: 0.225 G_B: 1.131 cycle_B: 0.188 idt_B: 0.320 \n",
            "(epoch: 188, iters: 174, time: 2.035, data: 0.002) D_A: 0.009 G_A: 0.894 cycle_A: 0.550 idt_A: 0.128 D_B: 0.023 G_B: 1.182 cycle_B: 0.278 idt_B: 0.176 \n",
            "End of epoch 188 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 189, iters: 76, time: 0.552, data: 0.002) D_A: 0.016 G_A: 0.996 cycle_A: 1.309 idt_A: 0.181 D_B: 0.058 G_B: 0.506 cycle_B: 0.495 idt_B: 0.460 \n",
            "(epoch: 189, iters: 176, time: 0.552, data: 0.002) D_A: 0.191 G_A: 0.789 cycle_A: 1.259 idt_A: 0.150 D_B: 0.071 G_B: 1.055 cycle_B: 0.323 idt_B: 0.497 \n",
            "End of epoch 189 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 190, iters: 78, time: 0.548, data: 0.005) D_A: 0.029 G_A: 1.018 cycle_A: 0.728 idt_A: 0.067 D_B: 0.068 G_B: 0.584 cycle_B: 0.154 idt_B: 0.232 \n",
            "(epoch: 190, iters: 178, time: 2.144, data: 0.002) D_A: 0.067 G_A: 0.905 cycle_A: 1.027 idt_A: 0.090 D_B: 0.051 G_B: 0.681 cycle_B: 0.184 idt_B: 0.289 \n",
            "saving the model at the end of epoch 190, iters 37620\n",
            "End of epoch 190 / 612 \t Time Taken: 105 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 191, iters: 80, time: 0.553, data: 0.001) D_A: 0.018 G_A: 1.035 cycle_A: 0.592 idt_A: 0.146 D_B: 0.027 G_B: 1.241 cycle_B: 0.340 idt_B: 0.254 \n",
            "(epoch: 191, iters: 180, time: 0.548, data: 0.002) D_A: 0.016 G_A: 0.930 cycle_A: 0.862 idt_A: 0.118 D_B: 0.030 G_B: 1.030 cycle_B: 0.228 idt_B: 0.266 \n",
            "End of epoch 191 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 192, iters: 82, time: 0.552, data: 0.002) D_A: 0.012 G_A: 1.074 cycle_A: 0.408 idt_A: 0.098 D_B: 0.150 G_B: 0.407 cycle_B: 0.306 idt_B: 0.209 \n",
            "(epoch: 192, iters: 182, time: 2.170, data: 0.008) D_A: 0.022 G_A: 0.984 cycle_A: 0.866 idt_A: 0.244 D_B: 0.071 G_B: 0.603 cycle_B: 0.524 idt_B: 0.333 \n",
            "End of epoch 192 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 193, iters: 84, time: 0.551, data: 0.002) D_A: 0.004 G_A: 0.759 cycle_A: 0.893 idt_A: 0.099 D_B: 0.027 G_B: 0.710 cycle_B: 0.228 idt_B: 0.338 \n",
            "(epoch: 193, iters: 184, time: 0.553, data: 0.014) D_A: 0.005 G_A: 1.013 cycle_A: 1.539 idt_A: 0.112 D_B: 0.085 G_B: 0.540 cycle_B: 0.311 idt_B: 0.538 \n",
            "End of epoch 193 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 194, iters: 86, time: 0.553, data: 0.002) D_A: 0.007 G_A: 1.015 cycle_A: 0.638 idt_A: 0.129 D_B: 0.253 G_B: 0.348 cycle_B: 0.280 idt_B: 0.292 \n",
            "(epoch: 194, iters: 186, time: 2.017, data: 0.006) D_A: 0.058 G_A: 1.114 cycle_A: 1.141 idt_A: 0.115 D_B: 0.065 G_B: 1.093 cycle_B: 0.401 idt_B: 0.528 \n",
            "End of epoch 194 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 195, iters: 88, time: 0.552, data: 0.002) D_A: 0.011 G_A: 0.984 cycle_A: 0.565 idt_A: 0.058 D_B: 0.210 G_B: 0.810 cycle_B: 0.141 idt_B: 0.210 \n",
            "(epoch: 195, iters: 188, time: 0.554, data: 0.002) D_A: 0.011 G_A: 0.954 cycle_A: 0.996 idt_A: 0.139 D_B: 0.580 G_B: 0.049 cycle_B: 0.323 idt_B: 0.357 \n",
            "saving the model at the end of epoch 195, iters 38610\n",
            "End of epoch 195 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 196, iters: 90, time: 0.554, data: 0.005) D_A: 0.015 G_A: 1.119 cycle_A: 0.637 idt_A: 0.175 D_B: 0.034 G_B: 1.026 cycle_B: 0.442 idt_B: 0.218 \n",
            "(epoch: 196, iters: 190, time: 2.118, data: 0.005) D_A: 0.012 G_A: 0.945 cycle_A: 1.398 idt_A: 0.081 D_B: 0.063 G_B: 0.159 cycle_B: 0.237 idt_B: 0.495 \n",
            "End of epoch 196 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 197, iters: 92, time: 0.552, data: 0.002) D_A: 0.043 G_A: 0.670 cycle_A: 0.686 idt_A: 0.063 D_B: 0.169 G_B: 0.343 cycle_B: 0.155 idt_B: 0.370 \n",
            "(epoch: 197, iters: 192, time: 0.553, data: 0.002) D_A: 0.068 G_A: 1.044 cycle_A: 1.624 idt_A: 0.102 D_B: 0.022 G_B: 0.890 cycle_B: 0.257 idt_B: 0.552 \n",
            "End of epoch 197 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 198, iters: 94, time: 0.552, data: 0.002) D_A: 0.068 G_A: 1.278 cycle_A: 0.911 idt_A: 0.092 D_B: 0.164 G_B: 0.502 cycle_B: 0.261 idt_B: 0.311 \n",
            "(epoch: 198, iters: 194, time: 2.198, data: 0.002) D_A: 0.049 G_A: 1.205 cycle_A: 0.644 idt_A: 0.143 D_B: 0.036 G_B: 0.625 cycle_B: 0.428 idt_B: 0.261 \n",
            "End of epoch 198 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 199, iters: 96, time: 0.551, data: 0.002) D_A: 0.293 G_A: 0.096 cycle_A: 0.873 idt_A: 0.096 D_B: 0.024 G_B: 0.805 cycle_B: 0.251 idt_B: 0.288 \n",
            "(epoch: 199, iters: 196, time: 0.549, data: 0.002) D_A: 0.114 G_A: 0.526 cycle_A: 2.059 idt_A: 0.214 D_B: 0.055 G_B: 0.291 cycle_B: 0.489 idt_B: 0.667 \n",
            "End of epoch 199 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 200, iters: 98, time: 0.549, data: 0.002) D_A: 0.028 G_A: 1.052 cycle_A: 0.816 idt_A: 0.097 D_B: 0.083 G_B: 0.705 cycle_B: 0.262 idt_B: 0.333 \n",
            "(epoch: 200, iters: 198, time: 2.089, data: 0.002) D_A: 0.033 G_A: 1.011 cycle_A: 0.896 idt_A: 0.100 D_B: 0.051 G_B: 0.719 cycle_B: 0.222 idt_B: 0.274 \n",
            "saving the model at the end of epoch 200, iters 39600\n",
            "End of epoch 200 / 612 \t Time Taken: 104 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 201, iters: 100, time: 0.557, data: 0.429) D_A: 0.009 G_A: 1.051 cycle_A: 0.706 idt_A: 0.166 D_B: 0.072 G_B: 0.738 cycle_B: 0.412 idt_B: 0.199 \n",
            "End of epoch 201 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 202, iters: 2, time: 0.564, data: 0.002) D_A: 0.007 G_A: 0.853 cycle_A: 0.935 idt_A: 0.121 D_B: 0.036 G_B: 0.215 cycle_B: 0.362 idt_B: 0.319 \n",
            "(epoch: 202, iters: 102, time: 0.550, data: 0.000) D_A: 0.018 G_A: 0.983 cycle_A: 0.905 idt_A: 0.157 D_B: 0.142 G_B: 0.259 cycle_B: 0.438 idt_B: 0.221 \n",
            "End of epoch 202 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 203, iters: 4, time: 2.243, data: 0.002) D_A: 0.048 G_A: 1.470 cycle_A: 0.690 idt_A: 0.159 D_B: 0.162 G_B: 0.301 cycle_B: 0.344 idt_B: 0.193 \n",
            "saving the latest model (epoch 203, total_iters 40000)\n",
            "(epoch: 203, iters: 104, time: 0.550, data: 0.002) D_A: 0.010 G_A: 0.846 cycle_A: 0.955 idt_A: 0.085 D_B: 0.121 G_B: 0.501 cycle_B: 0.210 idt_B: 0.267 \n",
            "End of epoch 203 / 612 \t Time Taken: 104 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 204, iters: 6, time: 0.555, data: 0.002) D_A: 0.021 G_A: 0.728 cycle_A: 0.889 idt_A: 0.165 D_B: 0.137 G_B: 0.336 cycle_B: 0.481 idt_B: 0.351 \n",
            "(epoch: 204, iters: 106, time: 0.553, data: 0.000) D_A: 0.048 G_A: 0.688 cycle_A: 0.828 idt_A: 0.095 D_B: 0.184 G_B: 0.480 cycle_B: 0.242 idt_B: 0.292 \n",
            "End of epoch 204 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 205, iters: 8, time: 2.188, data: 0.002) D_A: 0.017 G_A: 0.918 cycle_A: 0.700 idt_A: 0.103 D_B: 0.048 G_B: 0.739 cycle_B: 0.332 idt_B: 0.339 \n",
            "(epoch: 205, iters: 108, time: 0.551, data: 0.004) D_A: 0.016 G_A: 0.389 cycle_A: 0.845 idt_A: 0.171 D_B: 0.137 G_B: 0.251 cycle_B: 0.409 idt_B: 0.275 \n",
            "saving the model at the end of epoch 205, iters 40590\n",
            "End of epoch 205 / 612 \t Time Taken: 104 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 206, iters: 10, time: 0.549, data: 0.002) D_A: 0.004 G_A: 0.983 cycle_A: 1.659 idt_A: 0.158 D_B: 0.069 G_B: 0.766 cycle_B: 0.521 idt_B: 0.679 \n",
            "(epoch: 206, iters: 110, time: 0.551, data: 0.004) D_A: 0.009 G_A: 0.953 cycle_A: 0.746 idt_A: 0.135 D_B: 0.115 G_B: 0.335 cycle_B: 0.567 idt_B: 0.345 \n",
            "End of epoch 206 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 207, iters: 12, time: 2.130, data: 0.006) D_A: 0.006 G_A: 0.964 cycle_A: 1.017 idt_A: 0.135 D_B: 0.230 G_B: 0.239 cycle_B: 0.426 idt_B: 0.244 \n",
            "(epoch: 207, iters: 112, time: 0.552, data: 0.002) D_A: 0.006 G_A: 0.987 cycle_A: 0.837 idt_A: 0.167 D_B: 0.012 G_B: 1.007 cycle_B: 0.451 idt_B: 0.290 \n",
            "End of epoch 207 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 208, iters: 14, time: 0.549, data: 0.002) D_A: 0.029 G_A: 0.773 cycle_A: 0.673 idt_A: 0.116 D_B: 0.116 G_B: 0.382 cycle_B: 0.344 idt_B: 0.214 \n",
            "(epoch: 208, iters: 114, time: 0.547, data: 0.002) D_A: 0.007 G_A: 1.120 cycle_A: 1.332 idt_A: 0.142 D_B: 0.094 G_B: 1.139 cycle_B: 0.349 idt_B: 0.270 \n",
            "End of epoch 208 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 209, iters: 16, time: 2.262, data: 0.003) D_A: 0.236 G_A: 0.384 cycle_A: 0.816 idt_A: 0.095 D_B: 0.039 G_B: 0.730 cycle_B: 0.269 idt_B: 0.259 \n",
            "(epoch: 209, iters: 116, time: 0.553, data: 0.006) D_A: 0.005 G_A: 1.026 cycle_A: 0.832 idt_A: 0.107 D_B: 0.214 G_B: 0.592 cycle_B: 0.371 idt_B: 0.269 \n",
            "End of epoch 209 / 612 \t Time Taken: 104 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 210, iters: 18, time: 0.550, data: 0.002) D_A: 0.006 G_A: 1.145 cycle_A: 0.681 idt_A: 0.087 D_B: 0.056 G_B: 0.905 cycle_B: 0.213 idt_B: 0.519 \n",
            "(epoch: 210, iters: 118, time: 0.553, data: 0.005) D_A: 0.025 G_A: 0.801 cycle_A: 0.604 idt_A: 0.186 D_B: 0.021 G_B: 0.779 cycle_B: 0.468 idt_B: 0.236 \n",
            "saving the model at the end of epoch 210, iters 41580\n",
            "End of epoch 210 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 211, iters: 20, time: 2.237, data: 0.002) D_A: 0.014 G_A: 0.922 cycle_A: 0.517 idt_A: 0.094 D_B: 0.032 G_B: 0.790 cycle_B: 0.271 idt_B: 0.174 \n",
            "(epoch: 211, iters: 120, time: 0.554, data: 0.007) D_A: 0.022 G_A: 0.539 cycle_A: 0.830 idt_A: 0.127 D_B: 0.175 G_B: 0.857 cycle_B: 0.363 idt_B: 0.376 \n",
            "End of epoch 211 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 212, iters: 22, time: 0.553, data: 0.005) D_A: 0.019 G_A: 0.980 cycle_A: 1.577 idt_A: 0.089 D_B: 0.206 G_B: 0.618 cycle_B: 0.269 idt_B: 0.425 \n",
            "(epoch: 212, iters: 122, time: 0.550, data: 0.003) D_A: 0.011 G_A: 1.165 cycle_A: 1.199 idt_A: 0.144 D_B: 0.094 G_B: 0.271 cycle_B: 0.429 idt_B: 0.559 \n",
            "End of epoch 212 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 213, iters: 24, time: 2.236, data: 0.002) D_A: 0.003 G_A: 1.050 cycle_A: 0.396 idt_A: 0.130 D_B: 0.233 G_B: 0.385 cycle_B: 0.303 idt_B: 0.149 \n",
            "(epoch: 213, iters: 124, time: 0.548, data: 0.002) D_A: 0.015 G_A: 0.754 cycle_A: 1.092 idt_A: 0.072 D_B: 0.188 G_B: 0.702 cycle_B: 0.231 idt_B: 0.375 \n",
            "End of epoch 213 / 612 \t Time Taken: 103 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 214, iters: 26, time: 0.551, data: 0.003) D_A: 0.010 G_A: 0.946 cycle_A: 1.088 idt_A: 0.135 D_B: 0.189 G_B: 0.984 cycle_B: 0.415 idt_B: 0.308 \n",
            "(epoch: 214, iters: 126, time: 0.543, data: 0.003) D_A: 0.007 G_A: 1.067 cycle_A: 0.667 idt_A: 0.141 D_B: 0.198 G_B: 0.647 cycle_B: 0.368 idt_B: 0.263 \n",
            "End of epoch 214 / 612 \t Time Taken: 102 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 215, iters: 28, time: 2.445, data: 0.004) D_A: 0.014 G_A: 0.838 cycle_A: 0.937 idt_A: 0.138 D_B: 0.215 G_B: 1.172 cycle_B: 0.459 idt_B: 0.358 \n"
          ]
        }
      ],
      "source": [
        "!python train.py --dataroot ./datasets/denoise_data --name denoise_experiment1 --model cycle_gan --preprocess resize_and_crop --crop_size 256 --n_epochs 512"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py --dataroot ./datasets/denoise_data/testA --name denoise_experiment1 --model test --no_dropout --preprocess crop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GuyLMgz39a2",
        "outputId": "ab2df7a5-0503-4ffb-de5c-239ae545ec7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ./datasets/denoise_data/testA \t[default: None]\n",
            "             dataset_mode: single                        \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: test                          \n",
            "             model_suffix:                               \n",
            "               n_layers_D: 3                             \n",
            "                     name: denoise_experiment1           \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_9blocks                \n",
            "                      ngf: 64                            \n",
            "               no_dropout: True                          \t[default: False]\n",
            "                  no_flip: False                         \n",
            "                     norm: instance                      \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: crop                          \t[default: resize_and_crop]\n",
            "              results_dir: ./results/                    \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                use_wandb: False                         \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [SingleDataset] was created\n",
            "initialize network with normal\n",
            "model [TestModel] was created\n",
            "loading the model from ./checkpoints/denoise_experiment1/latest_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 11.378 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/denoise_experiment1/test_latest\n",
            "processing (0000)-th image... ['./datasets/denoise_data/testA/Screen Shot 2022-08-08 at 5.56.32 PM.png']\n",
            "processing (0005)-th image... ['./datasets/denoise_data/testA/Screen Shot 2022-08-08 at 6.00.05 PM.png']\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "OCR Senior Project",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ioIrCVkgDZ0K_R63k7GTmtfCelai_Mxv",
      "authorship_tag": "ABX9TyOhMK8hqIWuh8TDp2CKtLTs",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}